(window.webpackJsonp=window.webpackJsonp||[]).push([[223],{715:function(t,s,a){"use strict";a.r(s);var n=a(2),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("img",{attrs:{src:"https://img.starfish.ink/common/faq-banner.png",alt:""}})]),t._v(" "),a("blockquote",[a("p",[t._v("大数据技术栈是现代互联网企业的技术基石，从"),a("strong",[t._v("分布式存储")]),t._v("到"),a("strong",[t._v("实时计算")]),t._v("，从"),a("strong",[t._v("离线分析")]),t._v("到"),a("strong",[t._v("流式处理")]),t._v("，每一项技术都承载着海量数据的处理挑战。本文档将"),a("strong",[t._v("最常考的大数据知识点")]),t._v("整理成"),a("strong",[t._v("标准话术")]),t._v("，涵盖Hadoop、Spark、Flink、Hive、Kafka等核心组件，助你在面试中游刃有余！")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🗺️-知识导航"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🗺️-知识导航"}},[t._v("#")]),t._v(" 🗺️ 知识导航")]),t._v(" "),a("h3",{attrs:{id:"🏷️-核心知识分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🏷️-核心知识分类"}},[t._v("#")]),t._v(" 🏷️ 核心知识分类")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("🏗️ 分布式存储类")]),t._v("：HDFS架构、副本机制、NameNode、DataNode、块存储")]),t._v(" "),a("li",[a("strong",[t._v("⚡ 批计算框架")]),t._v("：MapReduce原理、Spark架构、RDD机制、内存计算")]),t._v(" "),a("li",[a("strong",[t._v("🌊 流计算框架")]),t._v("：Flink架构、Watermark、窗口函数、状态管理")]),t._v(" "),a("li",[a("strong",[t._v("📊 数据仓库技术")]),t._v("：Hive架构、SQL解析、分区分桶、存储格式")]),t._v(" "),a("li",[a("strong",[t._v("🚀 消息队列")]),t._v("：Kafka架构、分区副本、生产消费、性能优化")]),t._v(" "),a("li",[a("strong",[t._v("🔧 资源调度")]),t._v("：YARN架构、资源管理、任务调度、容器化")]),t._v(" "),a("li",[a("strong",[t._v("💼 实战场景题")]),t._v("：技术选型、架构设计、性能调优、故障处理")])]),t._v(" "),a("h3",{attrs:{id:"🔑-面试话术模板"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🔑-面试话术模板"}},[t._v("#")]),t._v(" 🔑 面试话术模板")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[a("strong",[t._v("问题类型")])]),t._v(" "),a("th",[a("strong",[t._v("回答框架")])]),t._v(" "),a("th",[a("strong",[t._v("关键要点")])]),t._v(" "),a("th",[a("strong",[t._v("深入扩展")])])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("概念解释")])]),t._v(" "),a("td",[t._v("定义→架构→核心机制→应用场景")]),t._v(" "),a("td",[t._v("准确定义，突出优势")]),t._v(" "),a("td",[t._v("底层原理，源码分析")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("对比分析")])]),t._v(" "),a("td",[t._v("相同点→不同点→使用场景→选择建议")]),t._v(" "),a("td",[t._v("多维度对比")]),t._v(" "),a("td",[t._v("性能差异，实际应用")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("原理解析")])]),t._v(" "),a("td",[t._v("背景→架构设计→执行流程→关键机制")]),t._v(" "),a("td",[t._v("图解流程")]),t._v(" "),a("td",[t._v("深层实现，调优要点")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("优化实践")])]),t._v(" "),a("td",[t._v("问题现象→分析思路→解决方案→监控验证")]),t._v(" "),a("td",[t._v("实际案例")]),t._v(" "),a("td",[t._v("最佳实践，踩坑经验")])])])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🏗️-一、分布式存储类-hdfs核心"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🏗️-一、分布式存储类-hdfs核心"}},[t._v("#")]),t._v(" 🏗️ 一、分布式存储类（HDFS核心）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：HDFS是Hadoop生态的存储基石，通过主从架构、副本机制、分块存储实现海量数据的可靠存储和高并发访问。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-什么是hdfs-它的核心架构是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-什么是hdfs-它的核心架构是什么"}},[t._v("#")]),t._v(" 🎯 什么是HDFS？它的核心架构是什么？")]),t._v(" "),a("p",[a("strong",[t._v("HDFS（Hadoop Distributed File System）是什么？")])]),t._v(" "),a("p",[t._v("HDFS是Hadoop生态系统中的"),a("strong",[t._v("分布式文件系统")]),t._v("，专为存储超大文件而设计。它通过"),a("strong",[t._v("主从架构")]),t._v("实现数据的分布式存储，具有"),a("strong",[t._v("高容错性、高吞吐量、流式数据访问")]),t._v("的特点。")]),t._v(" "),a("p",[a("strong",[t._v("核心架构组件")]),t._v("：")]),t._v(" "),a("ol",[a("li",[a("p",[a("strong",[t._v("NameNode（主节点）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("存储文件系统的"),a("strong",[t._v("元数据")]),t._v("（文件目录结构、文件属性、Block位置信息）")]),t._v(" "),a("li",[t._v("管理文件系统的"),a("strong",[t._v("命名空间")])]),t._v(" "),a("li",[t._v("协调客户端对文件的访问")]),t._v(" "),a("li",[t._v("维护"),a("strong",[t._v("FSImage")]),t._v("（文件系统镜像）和"),a("strong",[t._v("EditLog")]),t._v("（编辑日志）")])])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("DataNode（从节点）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("存储实际的"),a("strong",[t._v("数据块（Block）")])]),t._v(" "),a("li",[t._v("定期向NameNode发送"),a("strong",[t._v("心跳")]),t._v("和"),a("strong",[t._v("Block报告")])]),t._v(" "),a("li",[t._v("执行数据块的创建、删除、复制操作")]),t._v(" "),a("li",[t._v("响应客户端的读写请求")])])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("Secondary NameNode")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("定期合并FSImage和EditLog，减轻NameNode负担")]),t._v(" "),a("li",[a("strong",[t._v("不是")]),t._v("NameNode的热备份，而是辅助节点")])])])]),t._v(" "),a("p",[a("strong",[t._v("核心特性")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("分块存储")]),t._v("：文件被切分成固定大小的Block（默认128MB），分布存储")]),t._v(" "),a("li",[a("strong",[t._v("副本机制")]),t._v("：每个Block默认有3个副本，保证数据可靠性")]),t._v(" "),a("li",[a("strong",[t._v("一写多读")]),t._v("：适合大文件的一次写入、多次读取场景")]),t._v(" "),a("li",[a("strong",[t._v("流式访问")]),t._v("：优化顺序读取，不适合随机访问")])]),t._v(" "),a("h3",{attrs:{id:"🎯-hdfs的读写流程是怎样的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-hdfs的读写流程是怎样的"}},[t._v("#")]),t._v(" 🎯 HDFS的读写流程是怎样的？")]),t._v(" "),a("p",[a("strong",[t._v("HDFS写入流程")]),t._v("：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("客户端请求")]),t._v("：客户端调用FileSystem.create()创建文件")]),t._v(" "),a("li",[a("strong",[t._v("NameNode验证")]),t._v("：检查文件是否存在、权限是否满足")]),t._v(" "),a("li",[a("strong",[t._v("返回输出流")]),t._v("：NameNode返回FSDataOutputStream给客户端")]),t._v(" "),a("li",[a("strong",[t._v("申请Block")]),t._v("：客户端向NameNode申请新的Block和DataNode列表")]),t._v(" "),a("li",[a("strong",[t._v("建立管道")]),t._v("：客户端与第一个DataNode建立连接，形成DataNode管道")]),t._v(" "),a("li",[a("strong",[t._v("数据传输")]),t._v("：数据以packet为单位在管道中传输")]),t._v(" "),a("li",[a("strong",[t._v("确认机制")]),t._v("：每个DataNode接收数据后发送确认给前一个节点")]),t._v(" "),a("li",[a("strong",[t._v("关闭流")]),t._v("：写完后关闭输出流，通知NameNode写入完成")])]),t._v(" "),a("p",[a("strong",[t._v("HDFS读取流程")]),t._v("：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("客户端请求")]),t._v("：调用FileSystem.open()打开文件")]),t._v(" "),a("li",[a("strong",[t._v("NameNode查询")]),t._v("：获取文件的Block列表和对应的DataNode位置")]),t._v(" "),a("li",[a("strong",[t._v("返回输入流")]),t._v("：NameNode返回FSDataInputStream给客户端")]),t._v(" "),a("li",[a("strong",[t._v("选择DataNode")]),t._v("：客户端选择最近的DataNode读取Block")]),t._v(" "),a("li",[a("strong",[t._v("数据传输")]),t._v("：直接从DataNode读取数据到客户端")]),t._v(" "),a("li",[a("strong",[t._v("切换Block")]),t._v("：读完一个Block后自动切换到下一个Block")]),t._v(" "),a("li",[a("strong",[t._v("关闭流")]),t._v("：读取完成后关闭输入流")])]),t._v(" "),a("p",[a("strong",[t._v("关键优化点")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("机架感知")]),t._v("：优先选择同机架的DataNode，减少网络传输")]),t._v(" "),a("li",[a("strong",[t._v("本地读取")]),t._v("：如果客户端和DataNode在同一节点，直接本地读取")]),t._v(" "),a("li",[a("strong",[t._v("缓存机制")]),t._v("：NameNode的元数据缓存在内存中，提升查询性能")])]),t._v(" "),a("h3",{attrs:{id:"🎯-hdfs的副本放置策略是什么-为什么这样设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-hdfs的副本放置策略是什么-为什么这样设计"}},[t._v("#")]),t._v(" 🎯 HDFS的副本放置策略是什么？为什么这样设计？")]),t._v(" "),a("p",[a("strong",[t._v("默认副本放置策略（3副本）")]),t._v("：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("第一个副本")]),t._v("：放在客户端所在节点（如果客户端在集群外，随机选择）")]),t._v(" "),a("li",[a("strong",[t._v("第二个副本")]),t._v("：放在不同机架的随机节点")]),t._v(" "),a("li",[a("strong",[t._v("第三个副本")]),t._v("：放在第二个副本同一机架的不同节点")])]),t._v(" "),a("p",[a("strong",[t._v("设计原理")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("可靠性")]),t._v("：不同机架保证机架故障时数据不丢失")]),t._v(" "),a("li",[a("strong",[t._v("性能")]),t._v("：同机架内有两个副本，读取时可就近访问")]),t._v(" "),a("li",[a("strong",[t._v("网络带宽")]),t._v("：跨机架只有一次数据传输，节省网络带宽")])]),t._v(" "),a("p",[a("strong",[t._v("机架感知的重要性")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("机架A: DataNode1, DataNode2\n机架B: DataNode3, DataNode4\n\n副本放置：\n- 第一副本：DataNode1（客户端节点）\n- 第二副本：DataNode3（不同机架）  \n- 第三副本：DataNode4（与第二副本同机架）\n")])])]),a("p",[a("strong",[t._v("容错能力分析")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("节点故障")]),t._v("：任何单节点故障，剩余副本正常服务")]),t._v(" "),a("li",[a("strong",[t._v("机架故障")]),t._v("：任何单机架故障，其他机架的副本继续服务")]),t._v(" "),a("li",[a("strong",[t._v("网络分区")]),t._v("：机架间网络故障时，仍能保证数据访问")])]),t._v(" "),a("h3",{attrs:{id:"🎯-namenode单点故障如何解决"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-namenode单点故障如何解决"}},[t._v("#")]),t._v(" 🎯 NameNode单点故障如何解决？")]),t._v(" "),a("p",[a("strong",[t._v("问题背景")]),t._v("：\nNameNode存储着整个文件系统的元数据，一旦宕机，整个HDFS集群不可用，是典型的单点故障问题。")]),t._v(" "),a("p",[a("strong",[t._v("解决方案")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Secondary NameNode（辅助方案）")])]),t._v(" "),a("ul",[a("li",[t._v("定期合并FSImage和EditLog")]),t._v(" "),a("li",[t._v("NameNode故障后可手动恢复，但会有数据丢失")]),t._v(" "),a("li",[a("strong",[t._v("不是真正的高可用方案")])])]),t._v(" "),a("p",[a("strong",[t._v("2. NameNode HA（推荐方案）")])]),t._v(" "),a("p",[a("strong",[t._v("架构设计")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Active NameNode")]),t._v("：提供正常服务")]),t._v(" "),a("li",[a("strong",[t._v("Standby NameNode")]),t._v("：热备节点，实时同步元数据")]),t._v(" "),a("li",[a("strong",[t._v("共享存储")]),t._v("：JournalNode集群或NFS，存储EditLog")]),t._v(" "),a("li",[a("strong",[t._v("ZooKeeper")]),t._v("：协调Active/Standby状态切换")]),t._v(" "),a("li",[a("strong",[t._v("ZKFC")]),t._v("：ZooKeeper FailoverController，监控NameNode健康状态")])]),t._v(" "),a("p",[a("strong",[t._v("故障切换流程")]),t._v("：")]),t._v(" "),a("ol",[a("li",[t._v("ZKFC监控到Active NameNode故障")]),t._v(" "),a("li",[t._v("通过ZooKeeper协调，选举新的Active")]),t._v(" "),a("li",[t._v("Standby NameNode升级为Active")]),t._v(" "),a("li",[t._v("客户端重新连接新的Active NameNode")])]),t._v(" "),a("p",[a("strong",[t._v("数据同步机制")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("EditLog写入共享存储（JournalNode）")]),t._v(" "),a("li",[t._v("Standby NameNode实时读取EditLog更新内存中的元数据")]),t._v(" "),a("li",[t._v("保证Active/Standby元数据一致性")])]),t._v(" "),a("p",[a("strong",[t._v("3. Federation（联邦架构）")])]),t._v(" "),a("ul",[a("li",[t._v("多个NameNode管理不同的命名空间")]),t._v(" "),a("li",[t._v("水平扩展NameNode的处理能力")]),t._v(" "),a("li",[t._v("每个NameNode独立，彼此故障不影响")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"⚡-二、批计算框架-mapreduce-spark"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#⚡-二、批计算框架-mapreduce-spark"}},[t._v("#")]),t._v(" ⚡ 二、批计算框架（MapReduce & Spark）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：批计算框架是大数据处理的核心，从MapReduce的磁盘计算到Spark的内存计算，体现了大数据技术的演进历程。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-mapreduce的工作原理是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-mapreduce的工作原理是什么"}},[t._v("#")]),t._v(" 🎯 MapReduce的工作原理是什么？")]),t._v(" "),a("p",[a("strong",[t._v("MapReduce是什么？")])]),t._v(" "),a("p",[t._v("MapReduce是一种"),a("strong",[t._v("分布式计算模型")]),t._v("，将复杂的数据处理任务分解为**Map（映射）"),a("strong",[t._v("和")]),t._v("Reduce（归约）**两个阶段，适合处理大规模数据集的批处理任务。")]),t._v(" "),a("p",[a("strong",[t._v("核心工作流程")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Input输入阶段")])]),t._v(" "),a("ul",[a("li",[t._v("输入数据被切分成多个InputSplit")]),t._v(" "),a("li",[t._v("每个Split由一个Map任务处理")]),t._v(" "),a("li",[t._v("典型Split大小等于HDFS Block大小（128MB）")])]),t._v(" "),a("p",[a("strong",[t._v("2. Map阶段")])]),t._v(" "),a("ul",[a("li",[t._v("Map任务读取InputSplit中的数据")]),t._v(" "),a("li",[t._v("执行用户自定义的map函数")]),t._v(" "),a("li",[t._v("输出key-value对到本地磁盘")]),t._v(" "),a("li",[t._v("进行分区（Partition）和排序（Sort）")])]),t._v(" "),a("p",[a("strong",[t._v("3. Shuffle阶段")]),t._v("（核心且复杂）")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Copy阶段")]),t._v("：Reduce任务从各个Map任务拷贝数据")]),t._v(" "),a("li",[a("strong",[t._v("Sort阶段")]),t._v("：对拷贝来的数据进行合并排序")]),t._v(" "),a("li",[a("strong",[t._v("Group阶段")]),t._v("：将相同key的value组合在一起")])]),t._v(" "),a("p",[a("strong",[t._v("4. Reduce阶段")])]),t._v(" "),a("ul",[a("li",[t._v("Reduce任务处理分组后的数据")]),t._v(" "),a("li",[t._v("执行用户自定义的reduce函数")]),t._v(" "),a("li",[t._v("输出最终结果到HDFS")])]),t._v(" "),a("p",[a("strong",[t._v("WordCount示例流程")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("输入：hello world hello hadoop\nMap输出：(hello,1), (world,1), (hello,1), (hadoop,1)\nShuffle后：(hello,[1,1]), (world,[1]), (hadoop,[1])\nReduce输出：(hello,2), (world,1), (hadoop,1)\n")])])]),a("p",[a("strong",[t._v("关键机制")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("容错性")]),t._v("：任务失败自动重试，数据副本保证可靠性")]),t._v(" "),a("li",[a("strong",[t._v("本地性")]),t._v("：优先在数据所在节点执行任务")]),t._v(" "),a("li",[a("strong",[t._v("推测执行")]),t._v("：慢任务会启动备份任务，提升整体性能")])]),t._v(" "),a("h3",{attrs:{id:"🎯-spark相比mapreduce有什么优势"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-spark相比mapreduce有什么优势"}},[t._v("#")]),t._v(" 🎯 Spark相比MapReduce有什么优势？")]),t._v(" "),a("p",[a("strong",[t._v("Spark是什么？")])]),t._v(" "),a("p",[t._v("Spark是基于"),a("strong",[t._v("内存计算")]),t._v("的分布式计算框架，提供了比MapReduce更高的性能和更丰富的API，支持批处理、流处理、机器学习、图计算等多种计算场景。")]),t._v(" "),a("p",[a("strong",[t._v("核心优势对比")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("对比维度")]),t._v(" "),a("th",[t._v("MapReduce")]),t._v(" "),a("th",[t._v("Spark")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("计算模型")])]),t._v(" "),a("td",[t._v("磁盘计算，Map-Reduce两阶段")]),t._v(" "),a("td",[t._v("内存计算，DAG多阶段")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("性能")])]),t._v(" "),a("td",[t._v("中间结果落盘，I/O开销大")]),t._v(" "),a("td",[t._v("内存缓存，性能提升10-100倍")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("易用性")])]),t._v(" "),a("td",[t._v("只有Map-Reduce API")]),t._v(" "),a("td",[t._v("提供多种高级API（SQL、ML、Graph）")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("容错机制")])]),t._v(" "),a("td",[t._v("数据副本 + 任务重试")]),t._v(" "),a("td",[t._v("RDD血统 + Checkpoint")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("实时性")])]),t._v(" "),a("td",[t._v("只支持批处理")]),t._v(" "),a("td",[t._v("支持流处理（Spark Streaming）")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("内存管理")])]),t._v(" "),a("td",[t._v("依赖OS内存管理")]),t._v(" "),a("td",[t._v("自主内存管理，统一内存模型")])])])]),t._v(" "),a("p",[a("strong",[t._v("Spark架构优势")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. RDD（弹性分布式数据集）")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("不可变")]),t._v("：一旦创建不可修改，保证数据一致性")]),t._v(" "),a("li",[a("strong",[t._v("分区")]),t._v("：数据分布在集群的多个节点上")]),t._v(" "),a("li",[a("strong",[t._v("容错")]),t._v("：通过血统（Lineage）实现故障恢复")]),t._v(" "),a("li",[a("strong",[t._v("延迟计算")]),t._v("：只有Action操作才触发实际计算")])]),t._v(" "),a("p",[a("strong",[t._v("2. DAG（有向无环图）")])]),t._v(" "),a("ul",[a("li",[t._v("将复杂的计算流程表示为DAG")]),t._v(" "),a("li",[t._v("优化器自动优化执行计划")]),t._v(" "),a("li",[t._v("避免不必要的磁盘I/O")])]),t._v(" "),a("p",[a("strong",[t._v("3. 内存计算")])]),t._v(" "),a("ul",[a("li",[t._v("中间结果缓存在内存中")]),t._v(" "),a("li",[t._v("大大减少磁盘I/O开销")]),t._v(" "),a("li",[t._v("特别适合迭代计算（机器学习）")])]),t._v(" "),a("p",[a("strong",[t._v("适用场景选择")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("MapReduce")]),t._v("：简单的ETL、大文件处理、对内存要求不高的场景")]),t._v(" "),a("li",[a("strong",[t._v("Spark")]),t._v("：复杂分析、机器学习、实时处理、交互式查询")])]),t._v(" "),a("h3",{attrs:{id:"🎯-spark的核心概念rdd是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-spark的核心概念rdd是什么"}},[t._v("#")]),t._v(" 🎯 Spark的核心概念RDD是什么？")]),t._v(" "),a("p",[a("strong",[t._v("RDD（Resilient Distributed Dataset）是什么？")])]),t._v(" "),a("p",[t._v("RDD是Spark的"),a("strong",[t._v("核心数据抽象")]),t._v("，代表一个不可变的、可分区的数据集合，分布在集群的多个节点上。它是Spark所有操作的基础。")]),t._v(" "),a("p",[a("strong",[t._v("RDD的核心特性")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 不可变性（Immutable）")])]),t._v(" "),a("ul",[a("li",[t._v("RDD一旦创建就不能修改")]),t._v(" "),a("li",[t._v("所有转换操作都会产生新的RDD")]),t._v(" "),a("li",[t._v("保证了数据的一致性和线程安全")])]),t._v(" "),a("p",[a("strong",[t._v("2. 分区性（Partitioned）")])]),t._v(" "),a("ul",[a("li",[t._v("RDD的数据分布在多个分区中")]),t._v(" "),a("li",[t._v("每个分区可以在不同的节点上并行处理")]),t._v(" "),a("li",[t._v("分区数影响并行度")])]),t._v(" "),a("p",[a("strong",[t._v("3. 容错性（Fault-tolerant）")])]),t._v(" "),a("ul",[a("li",[t._v("通过血统（Lineage）记录RDD的依赖关系")]),t._v(" "),a("li",[t._v("任何分区丢失都可以根据血统重新计算")]),t._v(" "),a("li",[t._v("无需数据复制，节省存储空间")])]),t._v(" "),a("p",[a("strong",[t._v("4. 惰性计算（Lazy Evaluation）")])]),t._v(" "),a("ul",[a("li",[t._v("Transformation操作不会立即执行")]),t._v(" "),a("li",[t._v("只有遇到Action操作才会触发实际计算")]),t._v(" "),a("li",[t._v("便于优化执行计划")])]),t._v(" "),a("p",[a("strong",[t._v("RDD操作类型")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("Transformation（转换操作）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("map()")]),t._v("：对每个元素应用函数")]),t._v(" "),a("li",[a("code",[t._v("filter()")]),t._v("：过滤满足条件的元素")]),t._v(" "),a("li",[a("code",[t._v("flatMap()")]),t._v("：扁平化映射")]),t._v(" "),a("li",[a("code",[t._v("union()")]),t._v("：合并两个RDD")]),t._v(" "),a("li",[a("code",[t._v("groupByKey()")]),t._v("：按key分组")]),t._v(" "),a("li",[a("code",[t._v("reduceByKey()")]),t._v("：按key归约")])]),t._v(" "),a("p",[a("strong",[t._v("Action（行动操作）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("collect()")]),t._v("：收集所有元素到Driver")]),t._v(" "),a("li",[a("code",[t._v("count()")]),t._v("：统计元素个数")]),t._v(" "),a("li",[a("code",[t._v("first()")]),t._v("：获取第一个元素")]),t._v(" "),a("li",[a("code",[t._v("save()")]),t._v("：保存到文件系统")]),t._v(" "),a("li",[a("code",[t._v("foreach()")]),t._v("：对每个元素执行操作")])]),t._v(" "),a("p",[a("strong",[t._v("RDD依赖关系")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("窄依赖（Narrow Dependency）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("父RDD的每个分区只被子RDD的一个分区依赖")]),t._v(" "),a("li",[t._v("支持pipeline优化")]),t._v(" "),a("li",[t._v("故障恢复效率高")]),t._v(" "),a("li",[t._v("例如：map、filter")])]),t._v(" "),a("p",[a("strong",[t._v("宽依赖（Wide Dependency）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("父RDD的每个分区被子RDD的多个分区依赖")]),t._v(" "),a("li",[t._v("需要Shuffle操作")]),t._v(" "),a("li",[t._v("故障恢复成本高")]),t._v(" "),a("li",[t._v("例如：groupByKey、join")])]),t._v(" "),a("h3",{attrs:{id:"🎯-spark的内存管理机制是怎样的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-spark的内存管理机制是怎样的"}},[t._v("#")]),t._v(" 🎯 Spark的内存管理机制是怎样的？")]),t._v(" "),a("p",[a("strong",[t._v("Spark统一内存模型")]),t._v("：")]),t._v(" "),a("p",[t._v("从Spark 1.6开始，引入了"),a("strong",[t._v("统一内存管理")]),t._v("（Unified Memory Management），将内存分为两大区域：")]),t._v(" "),a("p",[a("strong",[t._v("1. 堆内内存（On-Heap Memory）")])]),t._v(" "),a("p",[a("strong",[t._v("Reserved Memory（保留内存）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("固定300MB，用于系统内部对象")]),t._v(" "),a("li",[t._v("不参与内存分配")])]),t._v(" "),a("p",[a("strong",[t._v("User Memory（用户内存）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("占用（Heap - Reserved）* 0.25 = 25%")]),t._v(" "),a("li",[t._v("存储用户自定义数据结构")]),t._v(" "),a("li",[t._v("不受Spark管理")])]),t._v(" "),a("p",[a("strong",[t._v("Unified Memory（统一内存）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("占用（Heap - Reserved）* 0.75 = 75%")]),t._v(" "),a("li",[t._v("分为Storage Memory和Execution Memory")])]),t._v(" "),a("p",[a("strong",[t._v("Storage Memory（存储内存）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("用于缓存RDD、广播变量")]),t._v(" "),a("li",[t._v("默认占Unified Memory的50%")]),t._v(" "),a("li",[t._v("可以借用Execution Memory")])]),t._v(" "),a("p",[a("strong",[t._v("Execution Memory（执行内存）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("用于Shuffle、Join、Sort等计算")]),t._v(" "),a("li",[t._v("默认占Unified Memory的50%")]),t._v(" "),a("li",[t._v("可以借用Storage Memory（但有限制）")])]),t._v(" "),a("p",[a("strong",[t._v("2. 堆外内存（Off-Heap Memory）")])]),t._v(" "),a("ul",[a("li",[t._v("通过"),a("code",[t._v("spark.memory.offHeap.enabled=true")]),t._v("开启")]),t._v(" "),a("li",[t._v("避免GC影响，提升性能")]),t._v(" "),a("li",[t._v("主要用于存储序列化的数据")])]),t._v(" "),a("p",[a("strong",[t._v("内存借用机制")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("Execution可以借用Storage的空闲内存")]),t._v(" "),a("li",[t._v("Storage可以借用Execution的空闲内存")]),t._v(" "),a("li",[t._v("但Storage借用的内存在Execution需要时必须释放")]),t._v(" "),a("li",[t._v("Execution借用的内存不会被强制释放")])]),t._v(" "),a("p",[a("strong",[t._v("内存管理优势")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("动态调整")]),t._v("：根据实际需求动态分配内存")]),t._v(" "),a("li",[a("strong",[t._v("减少溢出")]),t._v("：避免固定分配导致的内存浪费")]),t._v(" "),a("li",[a("strong",[t._v("提升性能")]),t._v("：统一管理减少内存碎片")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🌊-三、流计算框架-flink核心"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🌊-三、流计算框架-flink核心"}},[t._v("#")]),t._v(" 🌊 三、流计算框架（Flink核心）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：Flink是新一代流计算引擎，以流为核心、批为特殊流的理念，提供低延迟、高吞吐、精确一次语义的流处理能力。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-flink的核心架构是什么-与spark-streaming有什么区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-flink的核心架构是什么-与spark-streaming有什么区别"}},[t._v("#")]),t._v(" 🎯 Flink的核心架构是什么？与Spark Streaming有什么区别？")]),t._v(" "),a("p",[a("strong",[t._v("Flink是什么？")])]),t._v(" "),a("p",[t._v("Apache Flink是一个"),a("strong",[t._v("流优先")]),t._v("的分布式计算框架，支持有界和无界数据流的处理。它提供"),a("strong",[t._v("低延迟、高吞吐量、Exactly-Once")]),t._v("语义的流处理能力。")]),t._v(" "),a("p",[a("strong",[t._v("Flink核心架构")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. JobManager（作业管理器）")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("JobMaster")]),t._v("：管理单个作业的生命周期")]),t._v(" "),a("li",[a("strong",[t._v("ResourceManager")]),t._v("：管理集群资源分配")]),t._v(" "),a("li",[a("strong",[t._v("Dispatcher")]),t._v("：提供REST接口接收作业提交")])]),t._v(" "),a("p",[a("strong",[t._v("2. TaskManager（任务管理器）")])]),t._v(" "),a("ul",[a("li",[t._v("实际执行任务的工作节点")]),t._v(" "),a("li",[t._v("每个TaskManager包含多个Task Slot")]),t._v(" "),a("li",[t._v("Task Slot是资源分配的基本单位")])]),t._v(" "),a("p",[a("strong",[t._v("3. Client（客户端）")])]),t._v(" "),a("ul",[a("li",[t._v("提交作业到集群")]),t._v(" "),a("li",[t._v("编译用户程序生成JobGraph")])]),t._v(" "),a("p",[a("strong",[t._v("Flink vs Spark Streaming 核心区别")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("对比维度")]),t._v(" "),a("th",[t._v("Flink")]),t._v(" "),a("th",[t._v("Spark Streaming")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("计算模型")])]),t._v(" "),a("td",[t._v("真正的流计算（流为核心）")]),t._v(" "),a("td",[t._v("微批处理（批为核心）")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("延迟")])]),t._v(" "),a("td",[t._v("毫秒级低延迟")]),t._v(" "),a("td",[t._v("秒级延迟")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("状态管理")])]),t._v(" "),a("td",[t._v("原生流状态管理")]),t._v(" "),a("td",[t._v("基于RDD的状态管理")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("容错机制")])]),t._v(" "),a("td",[t._v("Checkpoint + 状态快照")]),t._v(" "),a("td",[t._v("RDD血统恢复")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("窗口操作")])]),t._v(" "),a("td",[t._v("灵活的窗口API")]),t._v(" "),a("td",[t._v("基于批次的窗口")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("背压处理")])]),t._v(" "),a("td",[t._v("动态背压控制")]),t._v(" "),a("td",[t._v("静态批处理调整")])])])]),t._v(" "),a("p",[a("strong",[t._v("技术选型建议")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("低延迟要求")]),t._v("：选择Flink（毫秒级）")]),t._v(" "),a("li",[a("strong",[t._v("高吞吐批处理")]),t._v("：选择Spark（生态完整）")]),t._v(" "),a("li",[a("strong",[t._v("复杂状态管理")]),t._v("：选择Flink（原生支持）")]),t._v(" "),a("li",[a("strong",[t._v("机器学习场景")]),t._v("：选择Spark（MLlib完善）")])]),t._v(" "),a("h3",{attrs:{id:"🎯-flink的watermark机制是什么-如何处理乱序数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-flink的watermark机制是什么-如何处理乱序数据"}},[t._v("#")]),t._v(" 🎯 Flink的Watermark机制是什么？如何处理乱序数据？")]),t._v(" "),a("p",[a("strong",[t._v("Watermark是什么？")])]),t._v(" "),a("p",[t._v("Watermark是Flink中用于处理"),a("strong",[t._v("乱序数据")]),t._v("和"),a("strong",[t._v("事件时间窗口")]),t._v("的机制。它表示"),a("strong",[t._v("某个时间戳之前的所有事件都已经到达")]),t._v("的标记。")]),t._v(" "),a("p",[a("strong",[t._v("乱序数据的挑战")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("理想情况：事件按时间戳顺序到达\n实际情况：网络延迟、系统故障导致乱序\n时间戳： 1, 2, 3, 4, 5\n到达顺序：1, 3, 2, 5, 4\n")])])]),a("p",[a("strong",[t._v("Watermark工作原理")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Watermark生成")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Periodic Watermark")]),t._v("：定期生成（默认200ms）")]),t._v(" "),a("li",[a("strong",[t._v("Punctuated Watermark")]),t._v("：根据特定事件生成")])]),t._v(" "),a("p",[a("strong",[t._v("2. Watermark传播")])]),t._v(" "),a("ul",[a("li",[t._v("从Source向下游传播")]),t._v(" "),a("li",[t._v("多输入流取最小Watermark")]),t._v(" "),a("li",[t._v("保证全局时间推进")])]),t._v(" "),a("p",[a("strong",[t._v("3. 窗口触发")])]),t._v(" "),a("ul",[a("li",[t._v("当Watermark >= 窗口结束时间时触发窗口计算")]),t._v(" "),a("li",[t._v("允许一定程度的延迟数据")])]),t._v(" "),a("p",[a("strong",[t._v("代码示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 生成Watermark")]),t._v("\nstream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("assignTimestampsAndWatermarks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("WatermarkStrategy")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("forBoundedOutOfOrderness")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Duration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ofSeconds")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("withTimestampAssigner")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("event"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timestamp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" event"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTimestamp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 时间窗口")]),t._v("\nstream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keyBy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getUserId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("window")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TumblingEventTimeWindows")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("minutes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("WindowProcessFunction")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 窗口处理逻辑")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("处理策略")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 允许延迟（Allowed Lateness）")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("window")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TumblingEventTimeWindows")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("minutes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allowedLateness")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("minutes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 允许1分钟延迟")]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. 侧输出流（Side Output）")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("OutputTag")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" lateDataTag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("OutputTag")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"late-data"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SingleOutputStreamOperator")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Result")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stream\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("window")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allowedLateness")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("minutes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sideOutputLateData")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lateDataTag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取延迟数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataStream")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" lateData "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSideOutput")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lateDataTag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("最佳实践")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("根据业务需求设置合理的延迟容忍度")]),t._v(" "),a("li",[t._v("监控延迟数据比例，调整Watermark策略")]),t._v(" "),a("li",[t._v("对于严格实时场景，使用处理时间窗口")])]),t._v(" "),a("h3",{attrs:{id:"🎯-flink的状态管理是如何实现的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-flink的状态管理是如何实现的"}},[t._v("#")]),t._v(" 🎯 Flink的状态管理是如何实现的？")]),t._v(" "),a("p",[a("strong",[t._v("Flink状态管理概述")]),t._v("：")]),t._v(" "),a("p",[t._v("状态是Flink流处理的核心功能，用于存储"),a("strong",[t._v("中间计算结果")]),t._v("和"),a("strong",[t._v("历史信息")]),t._v("，支持故障恢复和精确一次语义。")]),t._v(" "),a("p",[a("strong",[t._v("状态分类")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 按作用域分类")])]),t._v(" "),a("p",[a("strong",[t._v("Keyed State（键控状态）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("与特定key相关的状态")]),t._v(" "),a("li",[t._v("只能在KeyedStream上使用")]),t._v(" "),a("li",[t._v("状态自动分区和分发")])]),t._v(" "),a("p",[a("strong",[t._v("Operator State（算子状态）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("与算子实例绑定的状态")]),t._v(" "),a("li",[t._v("每个算子并行实例维护自己的状态")]),t._v(" "),a("li",[t._v("需要手动实现状态分发逻辑")])]),t._v(" "),a("p",[a("strong",[t._v("2. 按存储结构分类")])]),t._v(" "),a("p",[a("strong",[t._v("ValueState")]),t._v("：存储单个值")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ValueState")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" countState"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),t._v(" config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ValueStateDescriptor")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" descriptor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ValueStateDescriptor")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"count"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    countState "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRuntimeContext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getState")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("descriptor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("ListState")]),t._v("：存储元素列表")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ListState")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" eventListState"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("MapState")]),t._v("：存储Key-Value映射")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MapState")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" mapState"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("ReducingState")]),t._v("：存储单个值，新值通过ReduceFunction合并")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ReducingState")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" reducingState"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("AggregatingState")]),t._v("：类似ReducingState，但可以不同类型")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AggregatingState")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" aggState"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("状态存储后端（State Backend）")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. MemoryStateBackend")])]),t._v(" "),a("ul",[a("li",[t._v("状态存储在JVM堆内存中")]),t._v(" "),a("li",[t._v("适合状态较小的场景")]),t._v(" "),a("li",[t._v("性能最好，但容量有限")])]),t._v(" "),a("p",[a("strong",[t._v("2. FsStateBackend")])]),t._v(" "),a("ul",[a("li",[t._v("状态存储在文件系统（HDFS/S3）")]),t._v(" "),a("li",[t._v("适合中等规模状态")]),t._v(" "),a("li",[t._v("平衡性能和容量")])]),t._v(" "),a("p",[a("strong",[t._v("3. RocksDBStateBackend")])]),t._v(" "),a("ul",[a("li",[t._v("状态存储在本地RocksDB + 远程文件系统")]),t._v(" "),a("li",[t._v("适合大状态场景")]),t._v(" "),a("li",[t._v("支持增量checkpoint")])]),t._v(" "),a("p",[a("strong",[t._v("Checkpoint机制")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Checkpoint触发")])]),t._v(" "),a("ul",[a("li",[t._v("JobManager定期触发Checkpoint")]),t._v(" "),a("li",[t._v("基于分布式快照算法（Chandy-Lamport）")]),t._v(" "),a("li",[t._v("保证状态一致性")])]),t._v(" "),a("p",[a("strong",[t._v("2. Checkpoint流程")])]),t._v(" "),a("ul",[a("li",[t._v("JobManager向Source发送Checkpoint Barrier")]),t._v(" "),a("li",[t._v("Barrier在数据流中传播")]),t._v(" "),a("li",[t._v("算子收到Barrier时保存状态快照")]),t._v(" "),a("li",[t._v("所有算子完成后Checkpoint成功")])]),t._v(" "),a("p",[a("strong",[t._v("3. 故障恢复")])]),t._v(" "),a("ul",[a("li",[t._v("从最近的Checkpoint恢复状态")]),t._v(" "),a("li",[t._v("重播Checkpoint之后的数据")]),t._v(" "),a("li",[t._v("保证Exactly-Once语义")])]),t._v(" "),a("p",[a("strong",[t._v("状态优化策略")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("合理选择State Backend")]),t._v(" "),a("li",[t._v("设置合适的Checkpoint间隔")]),t._v(" "),a("li",[t._v("启用增量Checkpoint")]),t._v(" "),a("li",[t._v("清理过期状态（TTL）")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"📊-四、数据仓库技术-hive核心"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#📊-四、数据仓库技术-hive核心"}},[t._v("#")]),t._v(" 📊 四、数据仓库技术（Hive核心）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：Hive是Hadoop生态系统中的数据仓库软件，通过SQL接口简化大数据分析，是离线数据处理的核心组件。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-hive的架构原理是什么-sql是如何转换为mapreduce的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-hive的架构原理是什么-sql是如何转换为mapreduce的"}},[t._v("#")]),t._v(" 🎯 Hive的架构原理是什么？SQL是如何转换为MapReduce的？")]),t._v(" "),a("p",[a("strong",[t._v("Hive是什么？")])]),t._v(" "),a("p",[t._v("Hive是基于Hadoop的"),a("strong",[t._v("数据仓库软件")]),t._v("，提供"),a("strong",[t._v("SQL接口")]),t._v("来查询存储在HDFS上的数据。它将SQL查询转换为MapReduce、Spark或Tez作业来执行。")]),t._v(" "),a("p",[a("strong",[t._v("Hive核心架构")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Hive Client（客户端）")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("CLI")]),t._v("：命令行接口")]),t._v(" "),a("li",[a("strong",[t._v("HiveServer2")]),t._v("：提供JDBC/ODBC接口")]),t._v(" "),a("li",[a("strong",[t._v("Web Interface")]),t._v("：Web管理界面")])]),t._v(" "),a("p",[a("strong",[t._v("2. Hive Driver（驱动器）")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Compiler")]),t._v("：SQL编译器")]),t._v(" "),a("li",[a("strong",[t._v("Optimizer")]),t._v("：查询优化器")]),t._v(" "),a("li",[a("strong",[t._v("Executor")]),t._v("：执行引擎")])]),t._v(" "),a("p",[a("strong",[t._v("3. Hive MetaStore（元数据存储）")])]),t._v(" "),a("ul",[a("li",[t._v("存储表结构、分区信息、存储位置等元数据")]),t._v(" "),a("li",[t._v("通常使用MySQL等关系数据库存储")]),t._v(" "),a("li",[t._v("支持多个Hive实例共享元数据")])]),t._v(" "),a("p",[a("strong",[t._v("SQL转换MapReduce流程")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 语法分析（Parse）")])]),t._v(" "),a("ul",[a("li",[t._v("使用Antlr将SQL解析为抽象语法树（AST）")]),t._v(" "),a("li",[t._v("检查语法错误")])]),t._v(" "),a("p",[a("strong",[t._v("2. 语义分析（Semantic Analysis）")])]),t._v(" "),a("ul",[a("li",[t._v("将AST转换为查询块（Query Block）")]),t._v(" "),a("li",[t._v("验证表、列是否存在")]),t._v(" "),a("li",[t._v("类型检查和转换")])]),t._v(" "),a("p",[a("strong",[t._v("3. 逻辑计划生成")])]),t._v(" "),a("ul",[a("li",[t._v("生成逻辑执行计划")]),t._v(" "),a("li",[t._v("包括操作符树结构")])]),t._v(" "),a("p",[a("strong",[t._v("4. 逻辑优化")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("谓词下推")]),t._v("：将过滤条件尽早执行")]),t._v(" "),a("li",[a("strong",[t._v("列裁剪")]),t._v("：只读取需要的列")]),t._v(" "),a("li",[a("strong",[t._v("常量折叠")]),t._v("：预计算常量表达式")])]),t._v(" "),a("p",[a("strong",[t._v("5. 物理计划生成")])]),t._v(" "),a("ul",[a("li",[t._v("将逻辑计划转换为物理执行计划")]),t._v(" "),a("li",[t._v("决定使用MapReduce/Spark/Tez")])]),t._v(" "),a("p",[a("strong",[t._v("6. 物理优化")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("MapJoin")]),t._v("：小表broadcast到大表所在节点")]),t._v(" "),a("li",[a("strong",[t._v("分区裁剪")]),t._v("：只扫描相关分区")]),t._v(" "),a("li",[a("strong",[t._v("索引使用")]),t._v("：利用索引加速查询")])]),t._v(" "),a("p",[a("strong",[t._v("示例SQL转换过程")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" dept"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" employees \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" salary "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" dept"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("转换为MapReduce")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Map阶段")]),t._v("：过滤salary > 50000，输出(dept, 1)")]),t._v(" "),a("li",[a("strong",[t._v("Shuffle阶段")]),t._v("：按dept分组")]),t._v(" "),a("li",[a("strong",[t._v("Reduce阶段")]),t._v("：统计每个dept的count")])]),t._v(" "),a("h3",{attrs:{id:"🎯-hive的存储格式有哪些-各有什么特点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-hive的存储格式有哪些-各有什么特点"}},[t._v("#")]),t._v(" 🎯 Hive的存储格式有哪些？各有什么特点？")]),t._v(" "),a("p",[a("strong",[t._v("Hive支持多种存储格式")]),t._v("，不同格式适用于不同的场景和性能需求。")]),t._v(" "),a("p",[a("strong",[t._v("1. 行存储格式")])]),t._v(" "),a("p",[a("strong",[t._v("TextFile")])]),t._v(" "),a("ul",[a("li",[t._v("默认格式，纯文本存储")]),t._v(" "),a("li",[t._v("人类可读，便于调试")]),t._v(" "),a("li",[t._v("压缩率低，查询性能一般")]),t._v(" "),a("li",[t._v("适合小数据量、临时表")])]),t._v(" "),a("p",[a("strong",[t._v("SequenceFile")])]),t._v(" "),a("ul",[a("li",[t._v("Hadoop的二进制格式")]),t._v(" "),a("li",[t._v("支持压缩和分割")]),t._v(" "),a("li",[t._v("比TextFile性能好")]),t._v(" "),a("li",[t._v("适合中间数据存储")])]),t._v(" "),a("p",[a("strong",[t._v("2. 列存储格式")])]),t._v(" "),a("p",[a("strong",[t._v("ORC（Optimized Row Columnar）")])]),t._v(" "),a("ul",[a("li",[t._v("Hive专门优化的列式存储")]),t._v(" "),a("li",[a("strong",[t._v("优势")]),t._v("：\n"),a("ul",[a("li",[t._v("高压缩率（可达70%）")]),t._v(" "),a("li",[t._v("内置索引（Min/Max/Bloom Filter）")]),t._v(" "),a("li",[t._v("支持向量化查询")]),t._v(" "),a("li",[t._v("ACID事务支持")])])]),t._v(" "),a("li",[a("strong",[t._v("适用场景")]),t._v("：大数据分析、数仓查询")])]),t._v(" "),a("p",[a("strong",[t._v("Parquet")])]),t._v(" "),a("ul",[a("li",[t._v("通用的列式存储格式")]),t._v(" "),a("li",[a("strong",[t._v("优势")]),t._v("：\n"),a("ul",[a("li",[t._v("跨平台兼容性好")]),t._v(" "),a("li",[t._v("高效的编码和压缩")]),t._v(" "),a("li",[t._v("嵌套数据支持好")]),t._v(" "),a("li",[t._v("与Spark集成完善")])])]),t._v(" "),a("li",[a("strong",[t._v("适用场景")]),t._v("：多引擎数据共享")])]),t._v(" "),a("p",[a("strong",[t._v("3. 混合存储格式")])]),t._v(" "),a("p",[a("strong",[t._v("Avro")])]),t._v(" "),a("ul",[a("li",[t._v("支持模式演化")]),t._v(" "),a("li",[t._v("自描述数据格式")]),t._v(" "),a("li",[t._v("适合数据交换场景")])]),t._v(" "),a("p",[a("strong",[t._v("存储格式性能对比")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("格式")]),t._v(" "),a("th",[t._v("压缩率")]),t._v(" "),a("th",[t._v("查询性能")]),t._v(" "),a("th",[t._v("写入性能")]),t._v(" "),a("th",[t._v("兼容性")]),t._v(" "),a("th",[t._v("适用场景")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("TextFile")]),t._v(" "),a("td",[t._v("低")]),t._v(" "),a("td",[t._v("低")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("最好")]),t._v(" "),a("td",[t._v("调试、临时数据")])]),t._v(" "),a("tr",[a("td",[t._v("ORC")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("中")]),t._v(" "),a("td",[t._v("Hive生态")]),t._v(" "),a("td",[t._v("数仓分析")])]),t._v(" "),a("tr",[a("td",[t._v("Parquet")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("中")]),t._v(" "),a("td",[t._v("跨引擎")]),t._v(" "),a("td",[t._v("多引擎共享")])]),t._v(" "),a("tr",[a("td",[t._v("Avro")]),t._v(" "),a("td",[t._v("中")]),t._v(" "),a("td",[t._v("中")]),t._v(" "),a("td",[t._v("高")]),t._v(" "),a("td",[t._v("好")]),t._v(" "),a("td",[t._v("数据交换")])])])]),t._v(" "),a("p",[a("strong",[t._v("选择建议")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("数仓场景")]),t._v("：优先选择ORC")]),t._v(" "),a("li",[a("strong",[t._v("多引擎场景")]),t._v("：优先选择Parquet")]),t._v(" "),a("li",[a("strong",[t._v("实时写入")]),t._v("：考虑TextFile或Avro")]),t._v(" "),a("li",[a("strong",[t._v("存储成本敏感")]),t._v("：选择压缩率高的列式存储")])]),t._v(" "),a("h3",{attrs:{id:"🎯-hive的分区和分桶机制是什么-如何优化查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-hive的分区和分桶机制是什么-如何优化查询"}},[t._v("#")]),t._v(" 🎯 Hive的分区和分桶机制是什么？如何优化查询？")]),t._v(" "),a("p",[a("strong",[t._v("分区（Partition）机制")]),t._v("：")]),t._v(" "),a("p",[t._v("分区是Hive中的"),a("strong",[t._v("水平分割")]),t._v("技术，将表数据按照某个或多个列的值分割存储在不同的目录中。")]),t._v(" "),a("p",[a("strong",[t._v("分区的优势")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("查询优化")]),t._v("：只扫描相关分区，避免全表扫描")]),t._v(" "),a("li",[a("strong",[t._v("数据管理")]),t._v("：便于数据的增删改维护")]),t._v(" "),a("li",[a("strong",[t._v("并行度提升")]),t._v("：不同分区可以并行处理")])]),t._v(" "),a("p",[a("strong",[t._v("分区类型")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 静态分区")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 创建分区表")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" sales_data "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    product STRING"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    amount "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DOUBLE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" PARTITIONED "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nSTORED "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" ORC"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 插入数据到指定分区")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" sales_data "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PARTITION")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2024")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'phone'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. 动态分区")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 开启动态分区")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dynamic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dynamic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mode")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("nonstrict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 动态分区插入")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" sales_data "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PARTITION")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" product"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" amount"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" source_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("分桶（Bucket）机制")]),t._v("：")]),t._v(" "),a("p",[t._v("分桶是对数据进行"),a("strong",[t._v("hash分割")]),t._v("，将相同hash值的数据放在同一个文件中。")]),t._v(" "),a("p",[a("strong",[t._v("分桶的优势")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("Join优化")]),t._v("：相同key的数据在同一个桶中，避免shuffle")]),t._v(" "),a("li",[a("strong",[t._v("抽样查询")]),t._v("：可以高效地进行数据抽样")]),t._v(" "),a("li",[a("strong",[t._v("负载均衡")]),t._v("：数据均匀分布在各个文件中")])]),t._v(" "),a("p",[a("strong",[t._v("分桶示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 创建分桶表")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" user_data "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    name STRING"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    age "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CLUSTERED")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" BUCKETS\nSTORED "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" ORC"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 开启分桶")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enforce"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bucketing"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("查询优化策略")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 分区裁剪（Partition Pruning）")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 好的查询：只扫描特定分区")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" sales_data \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2024")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("AND")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 差的查询：全表扫描")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" sales_data \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" amount "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. 列裁剪（Column Pruning）")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 只查询需要的列")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" product "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" sales_data \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("year")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2024")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("3. 谓词下推（Predicate Pushdown）")])]),t._v(" "),a("ul",[a("li",[t._v("将过滤条件下推到存储层")]),t._v(" "),a("li",[t._v("减少数据传输量")])]),t._v(" "),a("p",[a("strong",[t._v("4. MapJoin优化")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 小表Join大表优化")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("auto"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("convert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapjoin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("smalltable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filesize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25000000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("5. 向量化执行")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 开启向量化查询")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vectorized"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execution"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enabled"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vectorized"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execution"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enabled"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("分区设计最佳实践")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("选择"),a("strong",[t._v("查询频繁")]),t._v("的列作为分区字段")]),t._v(" "),a("li",[t._v("避免"),a("strong",[t._v("分区过多")]),t._v("（建议<10000个）")]),t._v(" "),a("li",[t._v("分区大小控制在"),a("strong",[t._v("256MB-1GB")]),t._v("之间")]),t._v(" "),a("li",[t._v("使用"),a("strong",[t._v("多级分区")]),t._v("提高查询效率")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🚀-五、消息队列-kafka核心"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🚀-五、消息队列-kafka核心"}},[t._v("#")]),t._v(" 🚀 五、消息队列（Kafka核心）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：Kafka是分布式流处理平台的基石，通过分布式、高吞吐、低延迟的消息传递，连接数据的生产者和消费者。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-kafka的核心架构是什么-如何保证高性能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-kafka的核心架构是什么-如何保证高性能"}},[t._v("#")]),t._v(" 🎯 Kafka的核心架构是什么？如何保证高性能？")]),t._v(" "),a("p",[a("strong",[t._v("Kafka是什么？")])]),t._v(" "),a("p",[t._v("Apache Kafka是一个"),a("strong",[t._v("分布式流处理平台")]),t._v("，提供高吞吐量、低延迟的消息发布订阅服务，广泛用于实时数据管道和流式应用。")]),t._v(" "),a("p",[a("strong",[t._v("Kafka核心架构")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Broker（服务节点）")])]),t._v(" "),a("ul",[a("li",[t._v("Kafka集群中的服务器节点")]),t._v(" "),a("li",[t._v("负责存储和转发消息")]),t._v(" "),a("li",[t._v("通过ZooKeeper协调集群状态")])]),t._v(" "),a("p",[a("strong",[t._v("2. Topic（主题）")])]),t._v(" "),a("ul",[a("li",[t._v("消息的逻辑分类")]),t._v(" "),a("li",[t._v("生产者发送消息到Topic")]),t._v(" "),a("li",[t._v("消费者从Topic订阅消息")])]),t._v(" "),a("p",[a("strong",[t._v("3. Partition（分区）")])]),t._v(" "),a("ul",[a("li",[t._v("Topic的物理分割单位")]),t._v(" "),a("li",[t._v("每个分区是一个有序的消息队列")]),t._v(" "),a("li",[t._v("分区内消息有序，分区间无序")])]),t._v(" "),a("p",[a("strong",[t._v("4. Replica（副本）")])]),t._v(" "),a("ul",[a("li",[t._v("每个分区可以有多个副本")]),t._v(" "),a("li",[a("strong",[t._v("Leader Replica")]),t._v("：处理读写请求")]),t._v(" "),a("li",[a("strong",[t._v("Follower Replica")]),t._v("：从Leader同步数据")])]),t._v(" "),a("p",[a("strong",[t._v("5. Producer（生产者）")])]),t._v(" "),a("ul",[a("li",[t._v("发送消息到Kafka Topic")]),t._v(" "),a("li",[t._v("可以指定分区策略")])]),t._v(" "),a("p",[a("strong",[t._v("6. Consumer（消费者）")])]),t._v(" "),a("ul",[a("li",[t._v("从Kafka Topic消费消息")]),t._v(" "),a("li",[t._v("可以组成Consumer Group")])]),t._v(" "),a("p",[a("strong",[t._v("高性能设计原理")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 顺序写入")])]),t._v(" "),a("ul",[a("li",[t._v("消息追加到日志文件末尾")]),t._v(" "),a("li",[t._v("避免随机I/O，发挥磁盘顺序读写优势")]),t._v(" "),a("li",[t._v("顺序写性能接近内存")])]),t._v(" "),a("p",[a("strong",[t._v("2. 零拷贝（Zero Copy）")])]),t._v(" "),a("ul",[a("li",[t._v("使用sendfile()系统调用")]),t._v(" "),a("li",[t._v("数据直接从内核空间传输到网络")]),t._v(" "),a("li",[t._v("避免用户空间和内核空间的数据拷贝")])]),t._v(" "),a("p",[a("strong",[t._v("3. 批量处理")])]),t._v(" "),a("ul",[a("li",[t._v("生产者批量发送消息")]),t._v(" "),a("li",[t._v("减少网络请求次数")]),t._v(" "),a("li",[t._v("提升整体吞吐量")])]),t._v(" "),a("p",[a("strong",[t._v("4. 分区并行")])]),t._v(" "),a("ul",[a("li",[t._v("多个分区并行读写")]),t._v(" "),a("li",[t._v("提高并发处理能力")]),t._v(" "),a("li",[t._v("支持水平扩展")])]),t._v(" "),a("p",[a("strong",[t._v("5. 页缓存利用")])]),t._v(" "),a("ul",[a("li",[t._v("依赖操作系统页缓存")]),t._v(" "),a("li",[t._v("不在JVM堆中缓存数据")]),t._v(" "),a("li",[t._v("避免GC影响性能")])]),t._v(" "),a("p",[a("strong",[t._v("6. 压缩")])]),t._v(" "),a("ul",[a("li",[t._v("支持多种压缩算法（Gzip、Snappy、LZ4、ZSTD）")]),t._v(" "),a("li",[t._v("减少网络传输和存储开销")])]),t._v(" "),a("p",[a("strong",[t._v("性能调优参数")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 批量大小")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("batch.size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("16384")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("linger.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("5")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 压缩")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("compression.type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("lz4")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 副本确认")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("acks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("1")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 缓冲区大小")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("send.buffer.bytes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("131072")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("receive.buffer.bytes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("131072")]),t._v("\n")])])]),a("h3",{attrs:{id:"🎯-kafka如何保证消息的可靠性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-kafka如何保证消息的可靠性"}},[t._v("#")]),t._v(" 🎯 Kafka如何保证消息的可靠性？")]),t._v(" "),a("p",[a("strong",[t._v("可靠性挑战")]),t._v("：\n在分布式环境下，网络故障、节点宕机、磁盘损坏等问题都可能导致消息丢失或重复，Kafka需要在性能和可靠性之间找到平衡。")]),t._v(" "),a("p",[a("strong",[t._v("可靠性保证机制")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 副本机制（Replication）")])]),t._v(" "),a("p",[a("strong",[t._v("ISR（In-Sync Replica）集合")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("包含Leader和同步的Follower副本")]),t._v(" "),a("li",[t._v("只有ISR中的副本才能成为Leader")]),t._v(" "),a("li",[t._v("保证数据不丢失")])]),t._v(" "),a("p",[a("strong",[t._v("副本同步流程")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("Producer发送消息到Leader")]),t._v(" "),a("li",[t._v("Leader写入本地日志")]),t._v(" "),a("li",[t._v("Follower从Leader拉取消息")]),t._v(" "),a("li",[t._v("Follower写入本地日志并发送ACK给Leader")])]),t._v(" "),a("p",[a("strong",[t._v("2. ACK确认机制")])]),t._v(" "),a("p",[a("strong",[t._v("acks=0")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("生产者不等待任何确认")]),t._v(" "),a("li",[t._v("性能最高，可靠性最低")]),t._v(" "),a("li",[t._v("可能丢失消息")])]),t._v(" "),a("p",[a("strong",[t._v("acks=1")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("等待Leader确认")]),t._v(" "),a("li",[t._v("性能和可靠性的平衡")]),t._v(" "),a("li",[t._v("Leader故障可能丢失消息")])]),t._v(" "),a("p",[a("strong",[t._v("acks=-1/all")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("等待ISR中所有副本确认")]),t._v(" "),a("li",[t._v("可靠性最高，性能最低")]),t._v(" "),a("li",[t._v("配合"),a("code",[t._v("min.insync.replicas")]),t._v("使用")])]),t._v(" "),a("p",[a("strong",[t._v("3. 消息重试机制")])]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生产者重试配置")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("retries")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("Integer.MAX_VALUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("retry.backoff.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("100")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("request.timeout.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("30000")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("delivery.timeout.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("120000")]),t._v("\n")])])]),a("p",[a("strong",[t._v("4. 幂等性保证")])]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 开启幂等性")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("enable.idempotence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("true")]),t._v("\n")])])]),a("ul",[a("li",[t._v("生产者会为每个消息分配唯一的Sequence ID")]),t._v(" "),a("li",[t._v("Broker检测重复消息并丢弃")]),t._v(" "),a("li",[t._v("保证消息不重复")])]),t._v(" "),a("p",[a("strong",[t._v("5. 事务支持")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 事务生产者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),t._v(" props "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"transactional.id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my-transactional-id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"enable.idempotence"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("KafkaProducer")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" producer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("KafkaProducer")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("props"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nproducer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("initTransactions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    producer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("beginTransaction")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    producer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("send")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ProducerRecord")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    producer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitTransaction")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    producer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("abortTransaction")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("6. 消费者可靠性")])]),t._v(" "),a("p",[a("strong",[t._v("手动提交Offset")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 手动提交确保处理完成后再提交")]),t._v("\nconsumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Duration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ofMillis")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理消息...")]),t._v("\nconsumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitSync")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("消费者组故障转移")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("消费者故障时，其他消费者接管分区")]),t._v(" "),a("li",[t._v("通过心跳机制检测消费者状态")])]),t._v(" "),a("p",[a("strong",[t._v("可靠性配置最佳实践")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("高可靠性配置")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生产者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("acks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("all")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("retries")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("Integer.MAX_VALUE")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("enable.idempotence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("true")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("min.insync.replicas")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("2")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 消费者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("enable.auto.commit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("false")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("isolation.level")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("read_committed")]),t._v("\n")])])]),a("p",[a("strong",[t._v("高性能配置")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生产者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("acks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("1")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("batch.size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("32768")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("linger.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("10")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 消费者")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("enable.auto.commit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("true")]),t._v("\n")])])]),a("h3",{attrs:{id:"🎯-kafka消费者组的工作原理是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-kafka消费者组的工作原理是什么"}},[t._v("#")]),t._v(" 🎯 Kafka消费者组的工作原理是什么？")]),t._v(" "),a("p",[a("strong",[t._v("Consumer Group是什么？")])]),t._v(" "),a("p",[t._v("Consumer Group是Kafka中"),a("strong",[t._v("消费者的逻辑分组")]),t._v("，同一个Consumer Group中的消费者协作消费Topic的消息，每个分区只能被组内一个消费者消费。")]),t._v(" "),a("p",[a("strong",[t._v("核心工作原理")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 分区分配策略")])]),t._v(" "),a("p",[a("strong",[t._v("Range分配策略（默认）")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("按分区范围分配给消费者")]),t._v(" "),a("li",[t._v("可能导致分配不均衡")]),t._v(" "),a("li",[t._v("适合分区数是消费者数倍数的情况")])]),t._v(" "),a("p",[a("strong",[t._v("RoundRobin分配策略")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("轮询方式分配分区给消费者")]),t._v(" "),a("li",[t._v("分配更均衡")]),t._v(" "),a("li",[t._v("适合消费者订阅相同Topic的情况")])]),t._v(" "),a("p",[a("strong",[t._v("Sticky分配策略")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("尽量保持分区分配的粘性")]),t._v(" "),a("li",[t._v("Rebalance时减少分区重新分配")]),t._v(" "),a("li",[t._v("提高消费效率")])]),t._v(" "),a("p",[a("strong",[t._v("2. Coordinator协调机制")])]),t._v(" "),a("p",[a("strong",[t._v("Group Coordinator")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("每个Consumer Group对应一个Coordinator")]),t._v(" "),a("li",[t._v("负责管理组成员和分区分配")]),t._v(" "),a("li",[t._v("处理心跳和提交Offset")])]),t._v(" "),a("p",[a("strong",[t._v("工作流程")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("消费者加入Consumer Group")]),t._v(" "),a("li",[t._v("Coordinator选举Group Leader")]),t._v(" "),a("li",[t._v("Group Leader执行分区分配")]),t._v(" "),a("li",[t._v("Coordinator广播分配结果")])]),t._v(" "),a("p",[a("strong",[t._v("3. Rebalance机制")])]),t._v(" "),a("p",[a("strong",[t._v("触发条件")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("新消费者加入组")]),t._v(" "),a("li",[t._v("消费者离开组（正常关闭或故障）")]),t._v(" "),a("li",[t._v("Topic分区数变化")]),t._v(" "),a("li",[t._v("消费者订阅的Topic变化")])]),t._v(" "),a("p",[a("strong",[t._v("Rebalance流程")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("1. 消费者停止消费消息\n2. 消费者向Coordinator发送JoinGroup请求\n3. Coordinator收集所有消费者信息\n4. Coordinator选择Group Leader\n5. Group Leader执行分区分配算法\n6. Coordinator广播分配结果\n7. 消费者根据分配结果开始消费\n")])])]),a("p",[a("strong",[t._v("4. Offset管理")])]),t._v(" "),a("p",[a("strong",[t._v("自动提交")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("enable.auto.commit")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("true")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("auto.commit.interval.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("5000")]),t._v("\n")])])]),a("p",[a("strong",[t._v("手动提交")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 同步提交")]),t._v("\nconsumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitSync")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 异步提交")]),t._v("\nconsumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitAsync")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offsets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exception"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("exception "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        logger"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("error")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Commit failed"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exception"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("5. 心跳机制")])]),t._v(" "),a("div",{staticClass:"language-properties extra-class"},[a("pre",{pre:!0,attrs:{class:"language-properties"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 心跳间隔")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("heartbeat.interval.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("3000")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 会话超时")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("session.timeout.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("10000")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最大拉取间隔")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key attr-name"}},[t._v("max.poll.interval.ms")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token value attr-value"}},[t._v("300000")]),t._v("\n")])])]),a("p",[a("strong",[t._v("消费者代码示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),t._v(" props "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Properties")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9092"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my-group"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"auto.offset.reset"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"earliest"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nprops"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"partition.assignment.strategy"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.kafka.clients.consumer.StickyAssignor"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("KafkaConsumer")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" consumer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("KafkaConsumer")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("props"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nconsumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("subscribe")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Arrays")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("asList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my-topic"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConsumerRecords")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" records "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" consumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Duration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ofMillis")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConsumerRecord")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" record "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" records"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理消息")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("printf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"offset = %d, key = %s, value = %s%n"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n            record"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("offset")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" record"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("key")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" record"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    consumer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitAsync")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("最佳实践")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("合理设置消费者数量（不超过分区数）")]),t._v(" "),a("li",[t._v("选择合适的分区分配策略")]),t._v(" "),a("li",[t._v("监控Consumer Lag指标")]),t._v(" "),a("li",[t._v("处理Rebalance异常情况")]),t._v(" "),a("li",[t._v("合理设置心跳和会话超时参数")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🔧-六、资源调度-yarn核心"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🔧-六、资源调度-yarn核心"}},[t._v("#")]),t._v(" 🔧 六、资源调度（YARN核心）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：YARN是Hadoop 2.0的资源管理框架，实现了计算与存储分离，支持多种计算框架在同一集群中运行。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-yarn的架构原理是什么-与hadoop-1-0相比有什么优势"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-yarn的架构原理是什么-与hadoop-1-0相比有什么优势"}},[t._v("#")]),t._v(" 🎯 YARN的架构原理是什么？与Hadoop 1.0相比有什么优势？")]),t._v(" "),a("p",[a("strong",[t._v("YARN是什么？")])]),t._v(" "),a("p",[t._v("YARN（Yet Another Resource Negotiator）是Hadoop 2.0引入的"),a("strong",[t._v("资源管理框架")]),t._v("，负责集群资源的统一管理和调度，支持多种计算框架。")]),t._v(" "),a("p",[a("strong",[t._v("YARN核心架构")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. ResourceManager（资源管理器）")])]),t._v(" "),a("ul",[a("li",[t._v("集群的全局资源管理者")]),t._v(" "),a("li",[a("strong",[t._v("Scheduler")]),t._v("：负责资源分配，不监控应用状态")]),t._v(" "),a("li",[a("strong",[t._v("ApplicationManager")]),t._v("：管理应用的生命周期")])]),t._v(" "),a("p",[a("strong",[t._v("2. NodeManager（节点管理器）")])]),t._v(" "),a("ul",[a("li",[t._v("单个节点的资源管理者")]),t._v(" "),a("li",[t._v("监控节点资源使用情况")]),t._v(" "),a("li",[t._v("管理Container的生命周期")]),t._v(" "),a("li",[t._v("向ResourceManager汇报节点状态")])]),t._v(" "),a("p",[a("strong",[t._v("3. ApplicationMaster（应用管理器）")])]),t._v(" "),a("ul",[a("li",[t._v("每个应用有一个AM")]),t._v(" "),a("li",[t._v("向ResourceManager申请资源")]),t._v(" "),a("li",[t._v("与NodeManager通信启动Container")]),t._v(" "),a("li",[t._v("监控任务执行状态")])]),t._v(" "),a("p",[a("strong",[t._v("4. Container（容器）")])]),t._v(" "),a("ul",[a("li",[t._v("资源分配的基本单位")]),t._v(" "),a("li",[t._v("封装CPU、内存等资源")]),t._v(" "),a("li",[t._v("在NodeManager上运行具体任务")])]),t._v(" "),a("p",[a("strong",[t._v("YARN工作流程")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("1. Client提交应用到ResourceManager\n2. ResourceManager分配Container启动ApplicationMaster\n3. ApplicationMaster向ResourceManager注册\n4. ApplicationMaster请求资源运行任务\n5. ResourceManager分配Container给ApplicationMaster\n6. ApplicationMaster与NodeManager通信启动Container\n7. Container运行具体任务\n8. ApplicationMaster监控任务进度\n9. 应用完成后ApplicationMaster注销\n")])])]),a("p",[a("strong",[t._v("YARN vs Hadoop 1.0对比")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("对比维度")]),t._v(" "),a("th",[t._v("Hadoop 1.0")]),t._v(" "),a("th",[t._v("YARN")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("架构")])]),t._v(" "),a("td",[t._v("JobTracker + TaskTracker")]),t._v(" "),a("td",[t._v("ResourceManager + NodeManager + ApplicationMaster")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("扩展性")])]),t._v(" "),a("td",[t._v("4000节点瓶颈")]),t._v(" "),a("td",[t._v("万级节点支持")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("计算框架")])]),t._v(" "),a("td",[t._v("仅支持MapReduce")]),t._v(" "),a("td",[t._v("支持MapReduce、Spark、Storm等")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("资源利用率")])]),t._v(" "),a("td",[t._v("静态资源分配")]),t._v(" "),a("td",[t._v("动态资源分配")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("容错性")])]),t._v(" "),a("td",[t._v("JobTracker单点故障")]),t._v(" "),a("td",[t._v("ResourceManager HA")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("多租户")])]),t._v(" "),a("td",[t._v("不支持")]),t._v(" "),a("td",[t._v("支持资源隔离和配额管理")])])])]),t._v(" "),a("p",[a("strong",[t._v("YARN优势")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 资源利用率提升")])]),t._v(" "),a("ul",[a("li",[t._v("动态资源分配")]),t._v(" "),a("li",[t._v("不同框架共享集群资源")]),t._v(" "),a("li",[t._v("避免资源静态划分的浪费")])]),t._v(" "),a("p",[a("strong",[t._v("2. 扩展性增强")])]),t._v(" "),a("ul",[a("li",[t._v("分离资源管理和应用管理")]),t._v(" "),a("li",[t._v("单个ResourceManager可管理数万节点")]),t._v(" "),a("li",[t._v("ApplicationMaster分散了JobTracker压力")])]),t._v(" "),a("p",[a("strong",[t._v("3. 多框架支持")])]),t._v(" "),a("ul",[a("li",[t._v("统一资源管理平台")]),t._v(" "),a("li",[t._v("MapReduce、Spark、Flink等都可运行")]),t._v(" "),a("li",[t._v("避免重复建设集群")])]),t._v(" "),a("p",[a("strong",[t._v("4. 容错性改进")])]),t._v(" "),a("ul",[a("li",[t._v("ResourceManager支持HA")]),t._v(" "),a("li",[t._v("ApplicationMaster故障可重启")]),t._v(" "),a("li",[t._v("Container故障不影响其他任务")])]),t._v(" "),a("h3",{attrs:{id:"🎯-yarn的资源调度器有哪些-各有什么特点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-yarn的资源调度器有哪些-各有什么特点"}},[t._v("#")]),t._v(" 🎯 YARN的资源调度器有哪些？各有什么特点？")]),t._v(" "),a("p",[a("strong",[t._v("YARN调度器概述")]),t._v("：")]),t._v(" "),a("p",[t._v("YARN的调度器负责将集群资源分配给各个应用，不同的调度器采用不同的分配策略，适用于不同的应用场景。")]),t._v(" "),a("p",[a("strong",[t._v("1. FIFO Scheduler（先进先出调度器）")])]),t._v(" "),a("p",[a("strong",[t._v("特点")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("按提交时间顺序分配资源")]),t._v(" "),a("li",[t._v("简单易理解")]),t._v(" "),a("li",[t._v("不支持优先级")])]),t._v(" "),a("p",[a("strong",[t._v("适用场景")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("小集群或测试环境")]),t._v(" "),a("li",[t._v("单用户环境")]),t._v(" "),a("li",[t._v("对公平性要求不高的场景")])]),t._v(" "),a("p",[a("strong",[t._v("配置示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.resourcemanager.scheduler.class"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. Capacity Scheduler（容量调度器）")])]),t._v(" "),a("p",[a("strong",[t._v("核心特点")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("层次化队列")]),t._v("：支持多级队列嵌套")]),t._v(" "),a("li",[a("strong",[t._v("容量保证")]),t._v("：每个队列有最小容量保证")]),t._v(" "),a("li",[a("strong",[t._v("弹性资源")]),t._v("：队列可借用其他队列空闲资源")]),t._v(" "),a("li",[a("strong",[t._v("多租户")]),t._v("：不同队列可配置不同用户和权限")])]),t._v(" "),a("p",[a("strong",[t._v("队列配置")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 队列层次结构 --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.resource-calculator"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop.yarn.util.resource.DominantResourceCalculator"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 根队列配置 --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.root.queues"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("production,development,urgent"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 队列容量配置 --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.root.production.capacity"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("60"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.root.development.capacity"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("30"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.root.urgent.capacity"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("10"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 队列最大容量 --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.root.production.maximum-capacity"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("80"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[a("strong",[t._v("适用场景")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("企业多部门共享集群")]),t._v(" "),a("li",[t._v("需要资源隔离的场景")]),t._v(" "),a("li",[t._v("有SLA要求的生产环境")])]),t._v(" "),a("p",[a("strong",[t._v("3. Fair Scheduler（公平调度器）")])]),t._v(" "),a("p",[a("strong",[t._v("核心特点")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("公平共享")]),t._v("：资源在活跃应用间公平分配")]),t._v(" "),a("li",[a("strong",[t._v("抢占机制")]),t._v("：资源不足时可抢占其他应用资源")]),t._v(" "),a("li",[a("strong",[t._v("权重支持")]),t._v("：不同队列可设置不同权重")]),t._v(" "),a("li",[a("strong",[t._v("延迟调度")]),t._v("：支持数据本地性优化")])]),t._v(" "),a("p",[a("strong",[t._v("配置示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 启用Fair Scheduler --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.resourcemanager.scheduler.class"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 配置文件位置 --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.fair.allocation.file"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${HADOOP_CONF_DIR}/fair-scheduler.xml"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[a("strong",[t._v("fair-scheduler.xml配置")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("allocations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("queue")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("production"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("minResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("10000 mb,10 vcores"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("minResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("maxResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("90000 mb,90 vcores"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("maxResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("weight")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.0"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("weight")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("queue")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("queue")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("development"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("minResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5000 mb,5 vcores"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("minResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("maxResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("50000 mb,50 vcores"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("maxResources")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("weight")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("1.0"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("weight")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("queue")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- 抢占配置 --\x3e")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("fairSharePreemptionTimeout")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("60"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("fairSharePreemptionTimeout")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("fairSharePreemptionThreshold")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("0.5"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("fairSharePreemptionThreshold")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("allocations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[a("strong",[t._v("调度器对比")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("特性")]),t._v(" "),a("th",[t._v("FIFO")]),t._v(" "),a("th",[t._v("Capacity")]),t._v(" "),a("th",[t._v("Fair")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("公平性")])]),t._v(" "),a("td",[t._v("无")]),t._v(" "),a("td",[t._v("队列内公平")]),t._v(" "),a("td",[t._v("全局公平")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("资源保证")])]),t._v(" "),a("td",[t._v("无")]),t._v(" "),a("td",[t._v("容量保证")]),t._v(" "),a("td",[t._v("最小资源保证")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("抢占")])]),t._v(" "),a("td",[t._v("不支持")]),t._v(" "),a("td",[t._v("不支持")]),t._v(" "),a("td",[t._v("支持")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("多租户")])]),t._v(" "),a("td",[t._v("不支持")]),t._v(" "),a("td",[t._v("支持")]),t._v(" "),a("td",[t._v("支持")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("配置复杂度")])]),t._v(" "),a("td",[t._v("简单")]),t._v(" "),a("td",[t._v("中等")]),t._v(" "),a("td",[t._v("复杂")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("适用场景")])]),t._v(" "),a("td",[t._v("测试环境")]),t._v(" "),a("td",[t._v("企业生产")]),t._v(" "),a("td",[t._v("共享集群")])])])]),t._v(" "),a("p",[a("strong",[t._v("选择建议")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("FIFO")]),t._v("：测试和开发环境")]),t._v(" "),a("li",[a("strong",[t._v("Capacity")]),t._v("：多部门企业环境，需要严格资源隔离")]),t._v(" "),a("li",[a("strong",[t._v("Fair")]),t._v("：共享集群环境，需要动态公平分配")])]),t._v(" "),a("p",[a("strong",[t._v("调度器优化策略")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("合理设置队列容量和权重")]),t._v(" "),a("li",[t._v("启用资源抢占提高资源利用率")]),t._v(" "),a("li",[t._v("配置适当的调度间隔")]),t._v(" "),a("li",[t._v("监控队列资源使用情况")]),t._v(" "),a("li",[t._v("根据业务特点调整参数")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"💼-七、实战场景题-项目经验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#💼-七、实战场景题-项目经验"}},[t._v("#")]),t._v(" 💼 七、实战场景题（项目经验）")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("核心思想")]),t._v("：实战场景题是面试的重点，考察的是你在实际项目中运用大数据技术解决业务问题的能力。")])]),t._v(" "),a("h3",{attrs:{id:"🎯-如何设计一个实时数据处理架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-如何设计一个实时数据处理架构"}},[t._v("#")]),t._v(" 🎯 如何设计一个实时数据处理架构？")]),t._v(" "),a("p",[a("strong",[t._v("业务场景")]),t._v("：\n假设要设计一个"),a("strong",[t._v("电商实时推荐系统")]),t._v("，需要处理用户行为数据（点击、浏览、购买），实时更新用户画像和商品推荐。")]),t._v(" "),a("p",[a("strong",[t._v("架构设计思路")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 数据接入层")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("用户行为 → 埋点SDK → 消息队列(Kafka) → 实时处理\n")])])]),a("p",[a("strong",[t._v("技术选型")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("数据收集")]),t._v("：Flume、Logstash、自研Agent")]),t._v(" "),a("li",[a("strong",[t._v("消息队列")]),t._v("：Kafka（高吞吐、低延迟）")]),t._v(" "),a("li",[a("strong",[t._v("数据格式")]),t._v("：Avro/JSON（结构化数据）")])]),t._v(" "),a("p",[a("strong",[t._v("2. 实时计算层")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Kafka → Flink/Spark Streaming → 实时特征计算 → 存储层\n")])])]),a("p",[a("strong",[t._v("Flink实时处理示例")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用户行为流")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataStream")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserBehavior")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" behaviorStream "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" env\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("addSource")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FlinkKafkaConsumer")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user-behavior"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserBehaviorSchema")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" properties"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("assignTimestampsAndWatermarks")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("WatermarkStrategy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserBehavior")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("forBoundedOutOfOrderness")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Duration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ofSeconds")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("withTimestampAssigner")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("event"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" timestamp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" event"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTimestamp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 实时特征计算")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataStream")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserFeature")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" userFeatures "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" behaviorStream\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keyBy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserBehavior")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getUserId")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("window")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TumblingEventTimeWindows")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Time")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("minutes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("aggregate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserFeatureAggregator")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 输出到存储系统")]),t._v("\nuserFeatures"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("addSink")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RedisSink")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("3. 存储层")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("实时存储")]),t._v("：Redis/HBase（毫秒级读写）")]),t._v(" "),a("li",[a("strong",[t._v("离线存储")]),t._v("：HDFS/S3（历史数据存档）")]),t._v(" "),a("li",[a("strong",[t._v("OLAP存储")]),t._v("：ClickHouse/Druid（实时分析查询）")])]),t._v(" "),a("p",[a("strong",[t._v("4. 服务层")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("推荐服务")]),t._v("：基于实时特征的推荐算法")]),t._v(" "),a("li",[a("strong",[t._v("A/B测试")]),t._v("：实时效果监控和策略调整")]),t._v(" "),a("li",[a("strong",[t._v("API网关")]),t._v("：统一接口管理")])]),t._v(" "),a("p",[a("strong",[t._v("架构优化考虑")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("性能优化")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("Kafka分区数 = 消费者并发度")]),t._v(" "),a("li",[t._v("Flink并行度根据数据量动态调整")]),t._v(" "),a("li",[t._v("Redis集群化部署，避免热点数据")])]),t._v(" "),a("p",[a("strong",[t._v("容错处理")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("Kafka多副本保证数据不丢失")]),t._v(" "),a("li",[t._v("Flink Checkpoint机制保证exactly-once")]),t._v(" "),a("li",[t._v("多活部署避免单点故障")])]),t._v(" "),a("p",[a("strong",[t._v("扩展性设计")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("微服务架构，各组件独立扩展")]),t._v(" "),a("li",[t._v("消息队列支持水平扩展")]),t._v(" "),a("li",[t._v("存储分片策略支持数据增长")])]),t._v(" "),a("h3",{attrs:{id:"🎯-大数据平台的技术选型如何考虑"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-大数据平台的技术选型如何考虑"}},[t._v("#")]),t._v(" 🎯 大数据平台的技术选型如何考虑？")]),t._v(" "),a("p",[a("strong",[t._v("技术选型的考虑维度")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 业务需求分析")])]),t._v(" "),a("p",[a("strong",[t._v("数据量级")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("TB级别")]),t._v("：单机或小集群可处理")]),t._v(" "),a("li",[a("strong",[t._v("PB级别")]),t._v("：需要分布式大数据技术")]),t._v(" "),a("li",[a("strong",[t._v("EB级别")]),t._v("：需要专业的大数据架构")])]),t._v(" "),a("p",[a("strong",[t._v("实时性要求")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("离线批处理")]),t._v("：T+1数据处理，选择Hadoop/Spark")]),t._v(" "),a("li",[a("strong",[t._v("准实时")]),t._v("：分钟级延迟，选择Spark Streaming")]),t._v(" "),a("li",[a("strong",[t._v("实时")]),t._v("：秒级延迟，选择Flink/Storm")])]),t._v(" "),a("p",[a("strong",[t._v("查询模式")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("OLTP")]),t._v("：高并发事务，选择传统数据库")]),t._v(" "),a("li",[a("strong",[t._v("OLAP")]),t._v("：复杂分析查询，选择数据仓库")]),t._v(" "),a("li",[a("strong",[t._v("混合负载")]),t._v("：选择HTAP数据库")])]),t._v(" "),a("p",[a("strong",[t._v("2. 技术选型矩阵")])]),t._v(" "),a("p",[a("strong",[t._v("存储技术选型")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("数据类型")]),t._v(" "),a("th",[t._v("结构化数据")]),t._v(" "),a("th",[t._v("半结构化数据")]),t._v(" "),a("th",[t._v("非结构化数据")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("热数据")])]),t._v(" "),a("td",[t._v("MySQL/PostgreSQL")]),t._v(" "),a("td",[t._v("ElasticSearch")]),t._v(" "),a("td",[t._v("对象存储+CDN")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("温数据")])]),t._v(" "),a("td",[t._v("Hive/Presto")]),t._v(" "),a("td",[t._v("ElasticSearch")]),t._v(" "),a("td",[t._v("HDFS")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("冷数据")])]),t._v(" "),a("td",[t._v("数据湖(Delta Lake)")]),t._v(" "),a("td",[t._v("数据湖")]),t._v(" "),a("td",[t._v("对象存储")])])])]),t._v(" "),a("p",[a("strong",[t._v("计算框架选型")]),t._v("：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("场景")]),t._v(" "),a("th",[t._v("批处理")]),t._v(" "),a("th",[t._v("流处理")]),t._v(" "),a("th",[t._v("交互式查询")]),t._v(" "),a("th",[t._v("机器学习")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("推荐方案")])]),t._v(" "),a("td",[t._v("Spark")]),t._v(" "),a("td",[t._v("Flink")]),t._v(" "),a("td",[t._v("Presto/Trino")]),t._v(" "),a("td",[t._v("Spark MLlib")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("备选方案")])]),t._v(" "),a("td",[t._v("MapReduce")]),t._v(" "),a("td",[t._v("Kafka Streams")]),t._v(" "),a("td",[t._v("ClickHouse")]),t._v(" "),a("td",[t._v("TensorFlow on Spark")])])])]),t._v(" "),a("p",[a("strong",[t._v("3. 项目实践案例")])]),t._v(" "),a("p",[a("strong",[t._v("电商数据平台架构")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("数据源层：\n- 业务数据库（MySQL）\n- 埋点日志（Nginx/App）\n- 第三方API数据\n\n数据接入层：\n- 离线：Sqoop/DataX（数据库） + Flume（日志）\n- 实时：Kafka + Canal（binlog）\n\n数据存储层：\n- 数据湖：HDFS（原始数据）\n- 数据仓库：Hive（结构化数据）\n- 实时存储：HBase/Cassandra\n\n数据计算层：\n- 离线计算：Spark（ETL + 机器学习）\n- 实时计算：Flink（实时指标计算）\n- 即席查询：Presto（数据探索）\n\n数据服务层：\n- API网关：Spring Cloud Gateway\n- 缓存层：Redis Cluster\n- 搜索引擎：ElasticSearch\n")])])]),a("p",[a("strong",[t._v("技术选型决策过程")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("Step 1：需求调研")])]),t._v(" "),a("ul",[a("li",[t._v("数据量评估：日增1TB，总量100TB")]),t._v(" "),a("li",[t._v("查询QPS：1000/s，延迟<200ms")]),t._v(" "),a("li",[t._v("用户规模：100万DAU")])]),t._v(" "),a("p",[a("strong",[t._v("Step 2：POC验证")])]),t._v(" "),a("ul",[a("li",[t._v("搭建小规模测试环境")]),t._v(" "),a("li",[t._v("压测验证性能指标")]),t._v(" "),a("li",[t._v("评估开发和运维成本")])]),t._v(" "),a("p",[a("strong",[t._v("Step 3：架构设计")])]),t._v(" "),a("ul",[a("li",[t._v("考虑技术栈兼容性")]),t._v(" "),a("li",[t._v("评估团队技术能力")]),t._v(" "),a("li",[t._v("制定迁移和扩容方案")])]),t._v(" "),a("p",[a("strong",[t._v("选型最佳实践")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("优先选择成熟稳定的技术")])]),t._v(" "),a("li",[a("strong",[t._v("考虑团队技术栈和学习成本")])]),t._v(" "),a("li",[a("strong",[t._v("关注开源社区活跃度")])]),t._v(" "),a("li",[a("strong",[t._v("评估商业支持和服务")])]),t._v(" "),a("li",[a("strong",[t._v("制定技术演进路线图")])])]),t._v(" "),a("h3",{attrs:{id:"🎯-如何处理数据倾斜问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-如何处理数据倾斜问题"}},[t._v("#")]),t._v(" 🎯 如何处理数据倾斜问题？")]),t._v(" "),a("p",[a("strong",[t._v("数据倾斜是什么？")])]),t._v(" "),a("p",[t._v("数据倾斜是指在分布式计算中，"),a("strong",[t._v("数据分布不均匀")]),t._v("，导致某些节点处理的数据量远大于其他节点，成为性能瓶颈。")]),t._v(" "),a("p",[a("strong",[t._v("数据倾斜的表现")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("作业执行时间过长")]),t._v(" "),a("li",[t._v("某些Task执行时间远超其他Task")]),t._v(" "),a("li",[t._v("内存溢出（OOM）错误")]),t._v(" "),a("li",[t._v("集群资源利用率不均")])]),t._v(" "),a("p",[a("strong",[t._v("常见倾斜场景")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. Join倾斜")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 大表Join小表，某个key数据量巨大")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" big_table a\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" small_table b "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("date")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2024-01-01'")]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. GroupBy倾斜")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 某个分组的数据量过大")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" user_type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" user_behavior\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("date")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2024-01-01'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" user_type\n")])])]),a("p",[a("strong",[t._v("3. 分区倾斜")])]),t._v(" "),a("ul",[a("li",[t._v("按日期分区，某些日期数据量特别大")]),t._v(" "),a("li",[t._v("Hash分区，某些key的hash值集中")])]),t._v(" "),a("p",[a("strong",[t._v("数据倾斜解决方案")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 预处理阶段优化")])]),t._v(" "),a("p",[a("strong",[t._v("数据采样分析")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Spark数据采样")]),t._v("\nsample_df "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nskew_keys "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample_df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupBy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \\\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("orderBy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("desc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"count"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("limit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("过滤异常数据")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 过滤null值和异常值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("key")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IS")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" \n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("AND")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("key")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unknown'")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("AND")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("key")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n")])])]),a("p",[a("strong",[t._v("2. Join倾斜优化")])]),t._v(" "),a("p",[a("strong",[t._v("广播Join（Map-side Join）")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-scala extra-class"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Spark广播小表")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" broadcast_small "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("small_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" big_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" small_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" broadcast_small"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Join逻辑")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("加盐技术（Salting）")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-scala extra-class"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 大表加随机前缀")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" salted_big "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" big_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" salt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nextInt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token id function"}},[t._v("s")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("salt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("_")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 小表扩展")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" expanded_small "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" small_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" until "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token id function"}},[t._v("s")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("i")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("_")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Join后去除盐值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" salted_big"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expanded_small"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("salted_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("big_row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" small_row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 处理结果")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("两阶段聚合")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-scala extra-class"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 第一阶段：局部聚合加随机后缀")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" stage1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" salt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nextInt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token id function"}},[t._v("s")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("_")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("${")]),a("span",{pre:!0,attrs:{class:"token expression"}},[t._v("salt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 第二阶段：全局聚合去掉后缀")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" stage2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stage1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("salted_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" salted_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"_"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("3. 分区策略优化")])]),t._v(" "),a("p",[a("strong",[t._v("自定义分区器")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-scala extra-class"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" CustomPartitioner"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("partitions"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Partitioner "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" numPartitions"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" partitions\n    \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" getPartition"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Any")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" hotKey "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" isHotKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" \n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 热点数据分散到多个分区")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hashCode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("partitions "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("abs\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" \n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hashCode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" partitions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("abs\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("4. Hive中处理数据倾斜")])]),t._v(" "),a("p",[a("strong",[t._v("Map-side Join")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 开启Map Join")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("auto"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("convert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapjoin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("smalltable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filesize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25000000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("分桶表Join")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 创建分桶表避免倾斜")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" bucketed_table "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name STRING\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CLUSTERED")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" BUCKETS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("动态分区")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 使用动态分区均匀分布数据")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dynamic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("exec")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dynamic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mode")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("nonstrict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("5. Flink中处理数据倾斜")])]),t._v(" "),a("p",[a("strong",[t._v("自定义分区函数")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 自定义分区策略")]),t._v("\nstream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("partitionCustom")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Partitioner")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("partition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" numPartitions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("isHotKey")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 热点数据随机分区")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ThreadLocalRandom")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("current")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("nextInt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numPartitions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashCode")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" numPartitions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keySelector"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("strong",[t._v("监控和预防")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("监控Task执行时间分布")]),t._v(" "),a("li",[t._v("设置数据倾斜告警")]),t._v(" "),a("li",[t._v("定期分析热点数据")]),t._v(" "),a("li",[t._v("建立数据倾斜处理规范")])]),t._v(" "),a("h3",{attrs:{id:"🎯-大数据平台的监控体系如何建设"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-大数据平台的监控体系如何建设"}},[t._v("#")]),t._v(" 🎯 大数据平台的监控体系如何建设？")]),t._v(" "),a("p",[a("strong",[t._v("监控体系的重要性")]),t._v("：\n大数据平台涉及多个组件，数据链路复杂，需要完善的监控体系保证系统稳定运行和及时发现问题。")]),t._v(" "),a("p",[a("strong",[t._v("监控体系架构")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("1. 数据收集层")])]),t._v(" "),a("p",[a("strong",[t._v("系统监控")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("节点资源")]),t._v("：CPU、内存、磁盘、网络")]),t._v(" "),a("li",[a("strong",[t._v("JVM指标")]),t._v("：堆内存、GC、线程数")]),t._v(" "),a("li",[a("strong",[t._v("组件日志")]),t._v("：应用日志、错误日志")])]),t._v(" "),a("p",[a("strong",[t._v("业务监控")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("数据质量")]),t._v("：数据完整性、准确性、时效性")]),t._v(" "),a("li",[a("strong",[t._v("任务执行")]),t._v("：作业成功率、执行时间、资源消耗")]),t._v(" "),a("li",[a("strong",[t._v("数据流量")]),t._v("：吞吐量、延迟、积压")])]),t._v(" "),a("p",[a("strong",[t._v("监控工具选择")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("系统监控：Prometheus + Node Exporter\n应用监控：Micrometer + Prometheus\n日志收集：ELK Stack (Elasticsearch + Logstash + Kibana)\n链路追踪：Jaeger/Zipkin\n")])])]),a("p",[a("strong",[t._v("2. 监控指标设计")])]),t._v(" "),a("p",[a("strong",[t._v("基础设施监控")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Prometheus监控配置示例")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("groups")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" hadoop.rules\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("rules")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("alert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" HDFSNameNodeDown\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("expr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" up"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v('job="namenode"'),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" == 0\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 30s\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("labels")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("severity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" critical\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("summary")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HDFS NameNode is down"')]),t._v("\n      \n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("alert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DataNodeDiskUsage\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("expr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" (node_filesystem_size_bytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" node_filesystem_free_bytes) / node_filesystem_size_bytes "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v(" 0.85\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 2m\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("labels")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("severity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" warning\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("summary")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DataNode disk usage > 85%"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("应用层监控指标")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("Spark应用监控")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-scala extra-class"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 自定义Metrics")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsparkConf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.sql.streaming.metricsEnabled"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"true"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsparkConf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.metrics.conf.driver.source.jvm.class"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.spark.metrics.source.JvmSource"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 业务指标")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" counter "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkEnv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metricsSystem"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("counter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"custom.records.processed"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncounter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("recordCount"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("Flink应用监控")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Flink自定义Metrics")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MyMapFunction")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RichMapFunction")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Counter")]),t._v(" counter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),t._v(" config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("counter "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getRuntimeContext")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMetricGroup")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("counter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"records_processed"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Override")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        counter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("inc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toUpperCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("3. 告警机制")])]),t._v(" "),a("p",[a("strong",[t._v("告警规则设计")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# AlertManager告警规则")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("alert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" SparkJobFailure\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("expr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" spark_job_status"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v('status="failed"'),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v(" 0\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 0m\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("labels")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("severity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" critical\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("team")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("platform\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("summary")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Spark job {{ $labels.job_name }} failed"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Job has been failing for more than 0 minutes"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("alert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" KafkaConsumerLag\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("expr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" kafka_consumer_lag_sum "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),t._v(" 10000\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("for")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 5m\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("labels")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("severity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" warning\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("summary")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Kafka consumer lag is high"')]),t._v("\n")])])]),a("p",[a("strong",[t._v("告警渠道")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("企业微信/钉钉机器人")]),t._v(" "),a("li",[t._v("邮件通知")]),t._v(" "),a("li",[t._v("短信告警（严重故障）")]),t._v(" "),a("li",[t._v("PagerDuty（海外）")])]),t._v(" "),a("p",[a("strong",[t._v("4. 可视化监控大盘")])]),t._v(" "),a("p",[a("strong",[t._v("Grafana Dashboard设计")]),t._v("：")]),t._v(" "),a("p",[a("strong",[t._v("集群概览大盘")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"dashboard"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"title"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Big Data Platform Overview"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"panels"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"title"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"HDFS Storage Usage"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stat"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"targets"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"expr"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs_capacity_used_bytes / hdfs_capacity_total_bytes * 100"')]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"title"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"YARN Resource Usage"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"graph"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"targets"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token property"}},[t._v('"expr"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"yarn_cluster_memory_used / yarn_cluster_memory_total * 100"')]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("实时任务监控大盘")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("任务运行状态统计")]),t._v(" "),a("li",[t._v("数据处理吞吐量")]),t._v(" "),a("li",[t._v("任务执行延迟")]),t._v(" "),a("li",[t._v("错误率趋势")])]),t._v(" "),a("p",[a("strong",[t._v("5. 数据质量监控")])]),t._v(" "),a("p",[a("strong",[t._v("数据质量检查")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用Great Expectations进行数据质量检查")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" great_expectations "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" ge\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"data.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 数据完整性检查")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expect_column_to_exist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expect_column_values_to_not_be_null"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 数据准确性检查")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expect_column_values_to_be_between"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" min_value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("120")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 数据一致性检查")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expect_column_values_to_be_in_set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"status"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"active"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inactive"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("数据血缘监控")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Apache Atlas数据血缘")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyatlas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Atlas\n\nclient "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Atlas"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://atlas-server:21000"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"admin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"admin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建数据集实体")]),t._v("\ndataset "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"typeName"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DataSet"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"attributes"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_behavior"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"qualifiedName"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user_behavior@cluster1"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建处理过程实体")]),t._v("\nprocess "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"typeName"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Process"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"attributes"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"etl_user_behavior"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"outputs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("processed_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[a("strong",[t._v("监控最佳实践")]),t._v("：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("分层监控")]),t._v("：基础设施 → 组件 → 应用 → 业务")]),t._v(" "),a("li",[a("strong",[t._v("异常检测")]),t._v("：基于机器学习的异常识别")]),t._v(" "),a("li",[a("strong",[t._v("SLA定义")]),t._v("：明确服务等级协议")]),t._v(" "),a("li",[a("strong",[t._v("故障预案")]),t._v("：建立标准化应急响应流程")]),t._v(" "),a("li",[a("strong",[t._v("监控即代码")]),t._v("：监控配置版本化管理")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🎯-大数据面试备战指南"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎯-大数据面试备战指南"}},[t._v("#")]),t._v(" 🎯 大数据面试备战指南")]),t._v(" "),a("h3",{attrs:{id:"💡-高频考点top15"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#💡-高频考点top15"}},[t._v("#")]),t._v(" 💡 高频考点Top15")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("🏗️ HDFS架构原理")]),t._v(" - 分布式文件系统基础，副本机制和容错")]),t._v(" "),a("li",[a("strong",[t._v("⚡ MapReduce vs Spark")]),t._v(" - 批计算框架对比，内存计算优势")]),t._v(" "),a("li",[a("strong",[t._v("🌊 Flink流处理")]),t._v(" - 流计算引擎，Watermark和状态管理")]),t._v(" "),a("li",[a("strong",[t._v("📊 Hive数据仓库")]),t._v(" - SQL转MapReduce，存储格式优化")]),t._v(" "),a("li",[a("strong",[t._v("🚀 Kafka消息队列")]),t._v(" - 高性能消息系统，分区副本机制")]),t._v(" "),a("li",[a("strong",[t._v("🔧 YARN资源调度")]),t._v(" - 集群资源管理，调度器对比")]),t._v(" "),a("li",[a("strong",[t._v("💾 数据倾斜处理")]),t._v(" - 分布式计算常见问题和解决方案")]),t._v(" "),a("li",[a("strong",[t._v("🎯 技术选型")]),t._v(" - 不同场景下的技术选择策略")]),t._v(" "),a("li",[a("strong",[t._v("📈 监控运维")]),t._v(" - 大数据平台监控体系建设")]),t._v(" "),a("li",[a("strong",[t._v("⚙️ 性能调优")]),t._v(" - 各组件的参数优化和最佳实践")]),t._v(" "),a("li",[a("strong",[t._v("🔐 数据安全")]),t._v(" - Kerberos认证，权限管理")]),t._v(" "),a("li",[a("strong",[t._v("📦 容器化部署")]),t._v(" - Docker、Kubernetes在大数据中的应用")]),t._v(" "),a("li",[a("strong",[t._v("☁️ 云原生架构")]),t._v(" - 云上大数据解决方案")]),t._v(" "),a("li",[a("strong",[t._v("🤖 实时计算")]),t._v(" - 流批一体化架构设计")]),t._v(" "),a("li",[a("strong",[t._v("💡 架构演进")]),t._v(" - 从传统架构到现代数据湖架构")])]),t._v(" "),a("h3",{attrs:{id:"🎭-面试答题技巧"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎭-面试答题技巧"}},[t._v("#")]),t._v(" 🎭 面试答题技巧")]),t._v(" "),a("p",[a("strong",[t._v("📝 标准回答结构")])]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("背景介绍")]),t._v("（20秒） - 说明技术的应用背景和解决的问题")]),t._v(" "),a("li",[a("strong",[t._v("核心原理")]),t._v("（2分钟） - 深入讲解技术原理和关键机制")]),t._v(" "),a("li",[a("strong",[t._v("实践应用")]),t._v("（1分钟） - 结合实际项目说明如何使用")]),t._v(" "),a("li",[a("strong",[t._v("对比分析")]),t._v("（1分钟） - 与其他技术的对比优势")]),t._v(" "),a("li",[a("strong",[t._v("注意事项")]),t._v("（30秒） - 使用中的关键点和最佳实践")])]),t._v(" "),a("p",[a("strong",[t._v("🗣️ 表达话术模板")])]),t._v(" "),a("ul",[a("li",[t._v('"在我们项目中，面临的主要挑战是..."')]),t._v(" "),a("li",[t._v('"我们选择这个技术的原因是..."')]),t._v(" "),a("li",[t._v('"从性能角度来看，这种方案的优势在于..."')]),t._v(" "),a("li",[t._v('"在生产环境中，需要特别注意..."')]),t._v(" "),a("li",[t._v('"相比于传统方案，新架构带来的收益是..."')])]),t._v(" "),a("h3",{attrs:{id:"🚀-进阶加分点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🚀-进阶加分点"}},[t._v("#")]),t._v(" 🚀 进阶加分点")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("架构设计能力")]),t._v("：能设计完整的大数据处理架构")]),t._v(" "),a("li",[a("strong",[t._v("性能优化经验")]),t._v("：有具体的调优案例和效果数据")]),t._v(" "),a("li",[a("strong",[t._v("故障处理能力")]),t._v("：能快速定位和解决线上问题")]),t._v(" "),a("li",[a("strong",[t._v("技术深度")]),t._v("：了解底层原理和源码实现")]),t._v(" "),a("li",[a("strong",[t._v("业务理解")]),t._v("：能结合业务场景选择合适的技术方案")]),t._v(" "),a("li",[a("strong",[t._v("团队协作")]),t._v("：有跨团队合作的大数据项目经验")])]),t._v(" "),a("h3",{attrs:{id:"📚-延伸学习建议"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#📚-延伸学习建议"}},[t._v("#")]),t._v(" 📚 延伸学习建议")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("官方文档")]),t._v("：各组件的官方文档是最权威的学习资料")]),t._v(" "),a("li",[a("strong",[t._v("源码阅读")]),t._v("：深入理解核心组件的实现原理")]),t._v(" "),a("li",[a("strong",[t._v("实战项目")]),t._v("：搭建完整的大数据处理链路")]),t._v(" "),a("li",[a("strong",[t._v("技术博客")]),t._v("：关注知名公司的大数据技术分享")]),t._v(" "),a("li",[a("strong",[t._v("开源贡献")]),t._v("：参与开源项目，提升技术影响力")])]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"🎉-总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#🎉-总结"}},[t._v("#")]),t._v(" 🎉 总结")]),t._v(" "),a("p",[a("strong",[t._v("大数据技术栈是现代企业数字化转型的核心基础设施")]),t._v("，掌握这些技术不仅是技术能力的体现，更是解决业务问题的重要手段。")]),t._v(" "),a("p",[a("strong",[t._v("记住：面试官考察的不是死记硬背，而是你运用大数据技术解决实际业务问题的能力和思维方式。")])]),t._v(" "),a("p",[a("strong",[t._v("最后一句话")]),t._v("："),a("em",[t._v('"实践出真知，项目见真章"')]),t._v(" - 理论学习要与实际项目相结合，在实战中加深理解！")]),t._v(" "),a("hr"),t._v(" "),a("blockquote",[a("p",[t._v("💌 "),a("strong",[t._v("持续学习，拥抱变化！")]),a("br"),t._v("\n大数据技术日新月异，保持学习的热情，在技术的海洋中不断探索前行！")])])])}),[],!1,null,null,null);s.default=e.exports}}]);